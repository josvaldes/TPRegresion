---
title: "Examen año 2022"
author: "Jose Valdes"
date: "2023-07-12"
output:
  html_document:
    toc: yes
    code_folding: show
    toc_float: yes
    df_print: paged
    theme: united
    code_download: yes
  pdf_document:
    toc: yes
    toc_depth: '5'
  word_document:
    toc: yes
    toc_depth: '5'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
#limpio la memoria
rm( list= ls(all.names= TRUE) )  #remove all objects
gc( full= TRUE )                 #garbage collection
```
Se realiza validación de la instalación de los paquetes necesarios para ejecutar el script

```{r}
# Bibliotecas a cargar

check_packages <- function(packages) {
  if (all(packages %in% rownames(installed.packages()))) {
    TRUE
  } else{
    cat(
      "Instalar los siguientes packages antes de ejecutar el presente script\n",
      packages[!(packages %in% rownames(installed.packages()))],
      "\n"
    )
  }
}
packages_needed <- c("readxl","ggplot2","MVN","gridExtra","aod","MASS","carData","car","robustbase","leaps","olsrr","gamlss","lsr","ggpubr","lmtest","ResourceSelection","vcd","pROC","ROCR")

# Se llama a la funcion check_packages
check_packages(packages_needed)


library(readxl)
library(ggplot2)
library(MVN)
library(gridExtra)
library(aod)
library(MASS)
library(carData)
library(car)
library(robustbase)
library(leaps)
library(olsrr)
library(gamlss)
library(lsr)
library(ggpubr)
library(lmtest)
library(ResourceSelection)
library(vcd) 
library(pROC)
library(ROCR)

```


# <span style="color:darkred">Ejercicio 1 </span>
En el archivo preciocasas.xlsx se han registrado respecto de 100 viviendas las siguientes variables:
• impuestos: valor de impuesto anual de la vivienda.
• dormitorios cantidad de ambientes de la vivienda.
• banios: cantidad de baños del inmueble.
• estrena: si es a estrenar.
• precio: valor del alquiler de la vivienda
• tamanio: superficie total de la vivienda.

```{r}
library(readxl)
preciocasas<-read_excel("C:/Users/Josvaldes/Documents/Maestria/Austral/1ano/regresionAvanzada/TPRegresion/TPRegresion/examen/prueba/preciocasas.xlsx")
preciocasas
```

Se observa la distrubución  a través de un grafico:

Diagrama de dispersión
```{r}
library(ggplot2)
#Diagrama de dispersión precio en función del tamanio
dd1=ggplot(preciocasas, aes(tamanio, precio)) + 
  geom_point() + theme_minimal() + labs(title = "Diagrama de dispersi\u00F3n precio vs tamanio")
dd1
```

Por la distribución de los datos se creeria que se podria realizar un ajuste lineal.

## 1. Construir un modelo lineal simple para explicar el precio en función de la superficie y evaluar la bondad del ajuste.

```{r} 
modeleje1= lm(precio ~ tamanio, data = preciocasas )
summary(modeleje1)
```
- El intercepto (constante) tiene una estimación de -50926.255 y es significativamente diferente de cero, lo que indica que hay un valor base en el precio que no depende del tamaño.
- La variable "tamanio" tiene una estimación de 126.594, lo que significa que por cada unidad de aumento en el tamaño, se espera un aumento de 126.594 en el precio.
- Ambos coeficientes (intercepto y tamanio) son estadísticamente significativos, ya que los valores p son muy pequeños (<0.001).
- El coeficiente de determinación (R-cuadrado) es 0.6952, lo que indica que aproximadamente el 69.52% de la variabilidad en el precio se explica por el modelo.
- El error estándar residual es 56190, lo que indica la dispersión promedio de los residuos alrededor de la línea de regresión.
- El valor F es 223.5 con un valor p muy pequeño (<2.2e-16), lo que indica que el modelo es estadísticamente significativo y hay una relación lineal entre el tamaño y el precio.


## 2. Realizar un análisis diagnóstico y de puntos influyentes e indicar si el modelo es adecuado.

Análisis diagnóstico
-Normalidad
```{r}
shapiro.test(preciocasas$tamanio)
```
Se rechaza normalidad de la variable tamanio.

```{r}
shapiro.test(preciocasas$precio)
```

Análisis de normalidad multivariada - Test de Henze Zirkler

```{r}
#Analizamos normalidad bivariada
library(MVN)
#Usamos Test Henze-Zirkler para evaluar normalidad multivariada (bivariada en este caso)
respuesta_testHZ<-mvn(preciocasas , mvnTest = "hz")
respuesta_testHZ
```
Se realiza el test de correlación de Spearman debio a que no se observa que las variables sean normales entre ellas.

```{r}
cor.test(preciocasas$precio,preciocasas$tamanio, method="spearman", exact = FALSE)
```
Se rechaza la hipotesis nula de que no hay correlacion entre las variables, en tal sentido, se evidencia correlación entre las variables. Con relación a las variables análizadas precio y tamanio, estas corresponde a una correlacion positiva de alrededor del 74.17 %. A continuacion se presente un correlograma para un analisis mas amplio del conjunto de datos:

```{r}
library(corrplot)
corrplot(cor(preciocasas,method="s"))
```


normalidad de los residuos del modelo
```{r}
shapiro.test(modeleje1$residuals)
```
Tampoco los residuos del modelo son normales.


- homocedastisidad

```{r}
preciocasas2<-preciocasas
preciocasas2$prediccion <- modeleje1$fitted.values 
preciocasas2$residuos <- modeleje1$residuals

ggplot(data = preciocasas2, aes(x = prediccion, y = residuos)) + 
  geom_point(aes(color = residuos)) + 
  scale_color_gradient2(low = "blue3", mid = "grey", high = "red") + 
  geom_hline(yintercept = 0) + geom_segment(aes(xend = prediccion, yend = 0), alpha = 0.2) + 
  labs(title = "Distribución de los residuos", x = "predicción modelo", y = "residuo") + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none")
```
Paraciera tener estructura, los residuos se entienden que no son homocedasticos.

```{r}
library(lmtest) #carga la librería lmtest
bptest(modeleje1)
```
Se corrobora rechazo de la hipotesis nula de homecedastidad, los residuos son heterosedasticos.

- Independencia

```{r}
dwtest(modeleje1)
```
Se rechaza Ho, la hipótesis alternativa indica que existe una autocorrelación positiva mayor que cero en los residuos del modelo. Esto significa que hay evidencia de autocorrelación en los residuos del modelo, lo que sugiere que las observaciones están correlacionadas entre sí en cierta medida.



Outliers, puntos influyentes, y de alto leverage


Análisis de residuos y residuos estudentizados

```{r}
par(mfrow=c(2,2))
plot(modeleje1)
```

```{r}
summary(influence.measures(model = modeleje1))
```
```{r}

which(dfbetas(modeleje1)[,2]>1)
```
```{r}
n<-length(preciocasas$precio)
p<-length(modeleje1$coefficients)
which(dffits(modeleje1)>2 * sqrt(p / n))
```
Otros puntos influyentes

```{r}
library(car)
influencePlot(model = modeleje1)
```

```{r}
influenceIndexPlot(modeleje1, vars='Bonf', las=1,col='green')
```

```{r}
outlierTest(modeleje1)
```


Se confirma la observación No. 64 es un punto influyent y outlier. La Observación 6 y 9 son de que resaltan entre los demas puntos influyentes.

El modelo no es adecuado porque no cumple los supuestos, aunque el R cuadro explica un 69,21 % de la variable respuesta no cumplen los supuestos de normalidad, varianza constante e independencia. Se debe validar una transformación.


## 3. Realizar una transformación de la variable respuesta para lograr normalidad en la distribución de los residuos. Indicar si el modelo con esta transformación resulta adecuado.

```{r}
library(MASS)
box_cox_result <- boxcox(precio ~ tamanio, lambda = -2:2, data = preciocasas)
```
```{r}
# Se encuentra el valor óptimo de lambda que maximiza el logaritmo de verosimilitud
best_box_cox <- box_cox_result$x[which.max(box_cox_result$y)]

# Se ajusta un modelo de regresión lineal utilizando la variable dependiente "precio" elevada a la potencia óptima de lambda (best_box_cox) como la variable de respuesta y la variable independiente "tamanio".
model2eje1 <- lm((precio)^(best_box_cox) ~ tamanio, data = preciocasas)

summary(model2eje1)
```
En el modelo transformado se sigue observando que en general es significativo tanto de forma global como individual, el R cuadro baja un poco con relación al primer modelo pero aún sigue siendo representativo, 65.66%.

Se realiza analisis de los supuestos

**Normalidad**

```{r}
shapiro.test(model2eje1$residuals)
```
Se rechaza normalidad, pero se observa que se acerca a la zona de no rechazo.

**Homocedastisidad**

```{r}
preciocasas3<-preciocasas
preciocasas3$prediccion <- model2eje1$fitted.values 
preciocasas3$residuos <- model2eje1$residuals

ggplot(data = preciocasas3, aes(x = prediccion, y = residuos)) + 
  geom_point(aes(color = residuos)) + 
  scale_color_gradient2(low = "blue3", mid = "grey", high = "red") + 
  geom_hline(yintercept = 0) + geom_segment(aes(xend = prediccion, yend = 0), alpha = 0.2) + 
  labs(title = "Distribución de los residuos", x = "predicción modelo", y = "residuo") + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none")
```

```{r}
bptest(model2eje1)
```
Los residuos son homocedasticos, con relación al modelo anterior se observa que se mejora para ser residuos homocedasticos.

**Independencia**

```{r}
dwtest(model2eje1)
```
Se sigue rechazando Ho, existe autocorrelacion de los residuos del modelo.


Se intenta con un tercer modelo

```{r}
# Basado que el lamda optimo dio best_box_cox = 0.3030303, se intenta aproximandolo a cero
model3eje1 <- lm(log10(precio) ~ tamanio, data = preciocasas)
summary(model3eje1)
```

**Normalidad**
```{r}
shapiro.test(model3eje1$residuals)
```

Sigue sin cumplir normalidad

```{r}
model4eje1 <- lm((precio) ~ log10(tamanio), data = preciocasas)
summary(model4eje1)
```
**Normalidad**
```{r}
shapiro.test(model4eje1$residuals)
```
Sigue sin cumplir normalidad

```{r}
model5eje1 <- lm(log10(precio) ~ log10(tamanio), data = preciocasas)
summary(model5eje1)
```
**Normalidad**
```{r}
shapiro.test(model5eje1$residuals)
```
Se cumple el supuesto de normalidad, esto muy cerca de la zona de rechazo.


**Homocedasticidad**
```{r}
bptest(model5eje1)
```
Se cumple el supuesto de homocedastisidad de los residuos.


**Independencia**
```{r}
dwtest(model5eje1)
```
No se cumple independencia.

El modelo 5 no cumple los supuestos.

Función de cumplimientos de supuestos
```{r}
#Funcion de cumplimientos de supuestos
Respuesta <- matrix(0, nrow = 8, ncol = 1)

cumplimientoSupuestos <- function(modeloLineal) {
  #Supuesto de normalidad
  Normalidad=shapiro.test(modeloLineal$residuals)
    if (Normalidad$p.value>0.05){
      Respuesta[1,1]="Los residuos del modelo son normales basado en el test de Shapiro"
      
      p_value <- Normalidad$p.value
      texto <- paste("En este caso, como el valor p (", p_value, ") es mayor que el nivel de significancia (0.05), no se tiene suficiente evidencia para rechazar la hipótesis nula de normalidad. Por lo tanto, se puede considerar que los residuos del modelo siguen una distribución normal.")
      Respuesta[2,1] <- texto
      
      
    } else {
      
      Respuesta[1,1]="Los residuos del modelo no son normales basado en el test de Shapiro"
      
      p_value <- Normalidad$p.value
      texto <- paste("En este caso, como el valor p (", p_value, ") es menor que el nivel de significancia (0.05), se tiene suficiente evidencia para rechazar la hipótesis nula de normalidad. Por lo tanto, se puede considerar que los residuos del modelo no siguen una distribución normal.")
      Respuesta[2,1] <- texto
      
      
    }
  
  Respuesta[3,1]="----------------------------------------------------------------------------------------------------"
  
  #Supuesto de homocedastisidad
  homocedastisidad=bptest(modeloLineal)
    if (homocedastisidad$p.value>0.05){
      Respuesta[4,1]="Los errores del modelo son homocedastico basado en el test de Breusch-Pagan"
      p_value <- homocedastisidad$p.value
      texto <- paste("En este caso, como el valor p (", p_value, ") es mayor que el nivel de significancia establecido (0.05), no se tiene suficiente evidencia para rechazar la hipótesis nula de homocedasticidad. Por lo tanto, se puede considerar que los errores del modelo tienen varianzas constantes (homocedasticidad).")
      Respuesta[5,1] <- texto
      
      
    }else {
      Respuesta[4,1]="Los errores del modelo no son homocedastico basado en el test de Breusch-Pagan"
      p_value <- homocedastisidad$p.value
      texto <- paste("En este caso, como el valor p (", p_value, ") es menor que el nivel de significancia establecido (0.05), se tiene suficiente evidencia para rechazar la hipótesis nula de homocedasticidad. Por lo tanto, se puede considerar que los errores del modelo no tienen varianzas constantes (heterosedasticos).")
      Respuesta[5,1] <- texto
    }
  
   Respuesta[6,1]="----------------------------------------------------------------------------------------------------"
  #Supuesto de independencia
  independencia=dwtest(modeloLineal)
    if (independencia$p.value>0.05){
      Respuesta[7,1]="Los errores del modelo son independientes basado en el test de Durbin-Watson"
      p_value <- independencia$p.value
      texto <- paste("En este caso, como el valor p (", p_value, ") es mayor que el nivel de significancia establecido (0.05), se tiene suficiente evidencia para no rechazar la hipótesis nula de independencia de los errores. Por lo tanto, se puede concluir que no existe autocorrelación en los errores del modelo.")
      Respuesta[8,1] <- texto
    }else {
      Respuesta[7,1]="Los errores del modelo no son independientes basado en el test de Durbin-Watson"
      p_value <- independencia$p.value
      texto <- paste("En este caso, como el valor p (", p_value, ") es menor que el nivel de significancia establecido (0.05), se tiene suficiente evidencia para rechazar la hipótesis nula de independencia de los errores. Por lo tanto, se puede concluir que existe autocorrelación en los errores del modelo.")
      Respuesta[8,1] <- texto
    }
  
  return(Respuesta)
  
}

#cumplimientoSupuestos(model5eje1)
```
Se resume a continuación los supuestos de los modelos trabajados:

```{r}
cumplimientoSupuestos(model5eje1)
```


```{r}
cumplimientoSupuestos(model4eje1)
```

```{r}
cumplimientoSupuestos(model3eje1)
```
```{r}
cumplimientoSupuestos(model2eje1)
```


```{r}
cumplimientoSupuestos(modeleje1)
```

función resumen de cumplimientos de los modelos

```{r}
resumenCumplimiento <- function(cantidadModelos, ...) {
  modelos <- list(...)
  resultado <- matrix(0, nrow = cantidadModelos + 1, ncol = 5)
  
  # Nombre de la columna
  resultado[1, 1] <- "Modelos"
  
  # Obtener los nombres de los modelos como texto
  modelos_texto <- as.character(substitute(list(...)))[-1]
  
  for (i in 1:cantidadModelos) {
    # Asignar el nombre del modelo a la matriz resultado
    resultado[i + 1, 1] <- modelos_texto[i]
    
    # Nombre de la columna
    resultado[1, 2] <- "Normalidad"
    
    # Se obtiene el resultado de la función cumplimientoSupuestos
    resultado[i + 1, 2] <- cumplimientoSupuestos(modelos[[i]])[1, 1]
    
    #Reducción del texto
    if(resultado[i + 1, 2]=="Los residuos del modelo son normales basado en el test de Shapiro"){
      resultado[i + 1, 2] <- "Hay normalidad"
    }else{
      resultado[i + 1, 2] <- "No hay normalidad"
    }
    
    # Nombre de la columna 3
    resultado[1, 3] <- "Homocedasticidad"
    
    # Se obtiene el resultado de la función cumplimientoSupuestos
    resultado[i + 1, 3] <- cumplimientoSupuestos(modelos[[i]])[4, 1]
    resultado[i + 1, 3]
    #Reducción del texto
    if(resultado[i + 1, 3]=="Los errores del modelo son homocedastico basado en el test de Breusch-Pagan"){
      resultado[i + 1, 3] <- "Hay homocedasticidad"
    }else{
      resultado[i + 1, 3] <- "No hay homocedasticidad"
    }
    
    
    # Nombre de la columna 4
    resultado[1, 4] <- "Independencia"
    
    # Se obtiene el resultado de la función cumplimientoSupuestos
    resultado[i + 1, 4] <- cumplimientoSupuestos(modelos[[i]])[7, 1]
    resultado[i + 1, 4]
    #Reducción del texto
    if(resultado[i + 1, 4]=="Los errores del modelo son independientes basado en el test de Durbin-Watson"){
      resultado[i + 1, 4] <- "Hay independencia"
    }else{
      resultado[i + 1, 4] <- "No hay independencia"
    }
    
    # Nombre de la columna
    resultado[1, 5] <- "Cumplimiento"
    
    if (resultado[i + 1, 2] == "Hay normalidad" & resultado[i + 1, 3]=="Hay homocedasticidad" & resultado[i + 1, 4]=="Hay independencia") {
      resultado[i + 1, 5] <- "Si"
    } else {
      resultado[i + 1, 5] <- "No"
    }
  }
  
  return(resultado)

}
```



```{r}
resumenCumplimiento(5,modeleje1,model2eje1,model3eje1,model4eje1,model5eje1)
```

Ninguno de los modelos cumplen los supuestos.

```{r}
box_cox_result2 <- boxcox(precio ~ log10(tamanio), lambda = -2:2, data = preciocasas)
```

```{r}
# Se encuentra el valor óptimo de lambda que maximiza el logaritmo de verosimilitud
best_box_cox2 <- box_cox_result2$x[which.max(box_cox_result$y)]

# Se ajusta un modelo de regresión lineal utilizando la variable dependiente "precio" elevada a la potencia óptima de lambda (best_box_cox) como la variable de respuesta y la variable independiente "tamanio".
model2Box2eje1 <- lm((precio)^(best_box_cox2) ~ tamanio, data = preciocasas)

summary(model2Box2eje1)
```

```{r}
cumplimientoSupuestos(model2Box2eje1)
```

```{r}
model2Box22eje1 <- lm(log10(precio) ~ tamanio, data = preciocasas)

summary(model2Box22eje1)
```
```{r}
cumplimientoSupuestos(model2Box22eje1)
```


```{r}
box_cox_result3 <- boxcox(log10(precio) ~ log10(tamanio), lambda = -2:10, data = preciocasas)
```
```{r}
# Se encuentra el valor óptimo de lambda que maximiza el logaritmo de verosimilitud
best_box_cox3 <- box_cox_result3$x[which.max(box_cox_result$y)]

# Se ajusta un modelo de regresión lineal utilizando la variable dependiente "precio" elevada a la potencia óptima de lambda (best_box_cox) como la variable de respuesta y la variable independiente "tamanio".
model2Box3eje1 <- lm((precio)^(best_box_cox3) ~ tamanio, data = preciocasas)

summary(model2Box3eje1)
```
```{r}
cumplimientoSupuestos(model2Box3eje1)
```
De la revision se puede considerar que se debe utilizar un modelo robusto, esto debido a que no se logra normalizar los datos con las transformación box y cox. a continuación se presenta un resumen de los modelos utilizados:

```{r}
resumenCumplimiento(8,modeleje1,model2eje1,model3eje1,model4eje1,model5eje1,model2Box3eje1,model2Box2eje1,model2Box22eje1)
```


función para encontrar la mejor transformación box y cox (pendiente validar)

```{r}
mejorBoxYCox<- function(independiente, dependiente,datos){
  box_cox_result <- boxcox(independiente ~ dependiente, lambda = -2:2, data = datos)
  
  # Se encuentra el valor óptimo de lambda que maximiza el logaritmo de verosimilitud
  best_box_cox <- box_cox_result$x[which.max(box_cox_result$y)]

  # Se ajusta un modelo de regresión lineal utilizando la variable dependiente elevada a la potencia óptima de lambda (best_box_cox) como la variable de respuesta y la variable independiente si es distinta de cero, si es cero se realiza el logaritmo en base de 10 de la variable independiente.
  if (best_box_cox==0){
    model <- lm(log10(independiente) ~ dependiente, data = datos)
    
  } else {
    model <- lm((independiente)^(best_box_cox) ~ dependiente, data = datos)
  }
  
  
  
  return(cumplimientoSupuestos(model))
}

mejorBoxYCox(preciocasas$precio,preciocasas$tamanio,preciocasas)

```
## 4. Eliminar la observación 64 y ajustar nuevamente el segundo modelo evaluando su validez.

```{r}
# Eliminar la observación con id igual a 64
preciocasas_sin_obs64 <- subset(preciocasas, caso != 64)
preciocasas_sin_obs64
```

```{r}
modeleje1p4= lm(precio ~ tamanio, data = preciocasas_sin_obs64 )
summary(modeleje1p4)
```
```{r}
cumplimientoSupuestos(modeleje1p4)
```
Se observa que al retirar la observacion 64 el modelo lineal sensillo se sigue sin cumplir los supuesto, por otro lado, el r cuadro mejora a un 75.6%.


```{r}
promedioseje1p4 <- colMeans(preciocasas_sin_obs64)
ggplot(preciocasas_sin_obs64, aes(tamanio, precio)) + 
  geom_point() +
  geom_vline(xintercept=promedioseje1p4[7],linetype="dotted") + 
  geom_hline(yintercept=promedioseje1p4[6],linetype="dotted") +
  geom_smooth(method = "lm", se = TRUE, color = "black") +
  theme_minimal()
```


```{r}
ICcompleto<-predict(modeleje1p4, interval="confidence",level=0.95)
IPcompleto<-predict(modeleje1p4,newdata=data.frame(tamanio=preciocasas_sin_obs64$tamanio), interval="prediction",level=0.95)
datos<-data.frame(tamanio=preciocasas_sin_obs64$tamanio,precio=preciocasas_sin_obs64$precio,IPcompleto)             

ggplot(data = datos, mapping = aes(x = tamanio, y = precio)) + 
  geom_point(color = "firebrick", size = 2) + 
  labs(title = "Diagrama de dispersión con bandas de confianza y predicción", x = "tamanio") + 
  geom_line(aes(y=lwr), color="red" , linetype="dashed" ) +
  geom_line(aes(y=upr), color="red" , linetype="dashed" ) +
  geom_smooth(method = "lm", se = TRUE, color = "black") + 
  theme_bw() + theme(plot.title = element_text(hjust = 0.5)) 
```

```{r}
#Grafica del primer modelo con el conjunto de datos total
ICcompleto<-predict(modeleje1, interval="confidence",level=0.95)
IPcompleto<-predict(modeleje1,newdata=data.frame(tamanio=preciocasas$tamanio), interval="prediction",level=0.95)
datos<-data.frame(tamanio=preciocasas$tamanio,precio=preciocasas$precio,IPcompleto)             

ggplot(data = datos, mapping = aes(x = tamanio, y = precio)) + 
  geom_point(color = "firebrick", size = 2) + 
  labs(title = "Diagrama de dispersión con bandas de confianza y predicción", x = "tamanio") + 
  geom_line(aes(y=lwr), color="red" , linetype="dashed" ) +
  geom_line(aes(y=upr), color="red" , linetype="dashed" ) +
  geom_smooth(method = "lm", se = TRUE, color = "black") + 
  theme_bw() + theme(plot.title = element_text(hjust = 0.5))
```

```{r}
#GRafica del mejor modelo con transformacion
ICcompleto<-predict(model5eje1, interval="confidence",level=0.95)
IPcompleto<-predict(model5eje1,newdata=data.frame(tamanio=preciocasas$tamanio), interval="prediction",level=0.95)
datos<-data.frame(tamanio=preciocasas$tamanio,precio=preciocasas$precio,IPcompleto)             

ggplot(data = datos, mapping = aes(x = tamanio, y = precio)) + 
  geom_point(color = "firebrick", size = 2) + 
  labs(title = "Diagrama de dispersión con bandas de confianza y predicción", x = "tamanio") + 
  geom_line(aes(y=lwr), color="red" , linetype="dashed" ) +
  geom_line(aes(y=upr), color="red" , linetype="dashed" ) +
  geom_smooth(method = "lm", se = TRUE, color = "black") + 
  theme_bw() + theme(plot.title = element_text(hjust = 0.5))
```



función grafica con intervalos
```{r}
graficaMLIntervalos <- function(modelolineal,independiente,dependiente,dataset){
  ICcompleto<-predict(modelolineal, interval="confidence",level=0.95)
  IPcompleto<-predict(modelolineal,newdata=data.frame(independiente), interval="prediction",level=0.95)
  datos<-data.frame(independiente,dependiente,IPcompleto)             

 grafica <- ggplot(data = datos, mapping = aes(x = independiente, y = precio)) + 
    geom_point(color = "firebrick", size = 2) + 
    labs(title = "Diagrama de dispersión con bandas de confianza y predicción", x = "tamanio") + 
    geom_line(aes(y=lwr), color="red" , linetype="dashed" ) +
    geom_line(aes(y=upr), color="red" , linetype="dashed" ) +
    geom_smooth(method = "lm", se = TRUE, color = "black") + 
    theme_bw() + theme(plot.title = element_text(hjust = 0.5))
 
 return(grafica)
}

```

```{r}
tamanio=preciocasas_sin_obs64$tamanio
precio=preciocasas_sin_obs64$precio
graficaMLIntervalos(modeleje1p4,tamanio,precio,preciocasas_sin_obs64)
```
```{r}
graficaMLIntervalos(model5eje1,tamanio,precio,preciocasas)
```

## 5. Ajustar un modelo robusto y evaluar el promedio de los errores absolutos cometidos. Comparar con el mejor modelo lineal disponible.

```{r}
library(robustbase)
ajusterobP5 <- lmrob(precio ~ ., data = preciocasas)
summary(ajusterobP5)
```

Mejor modelo lineal basado en los errores
```{r}
#Promedios errores absolutos del modelo 1
m1<-summary(modeleje1)
print(paste("Modelo 1, errores: ", mean(abs(m1$residuals))))
#Promedios errores absolutos del modelo 2
m2<-summary(model2eje1)
print(paste("Modelo 2, errores: ", mean(abs(m2$residuals))))
#Promedios errores absolutos del modelo 3
m3<-summary(model3eje1)
print(paste("Modelo 3, errores: ", mean(abs(m3$residuals))))
#Promedios errores absolutos del modelo 4
m4<-summary(model4eje1)
print(paste("Modelo 4, errores: ", mean(abs(m4$residuals))))
#Promedios errores absolutos del modelo 5
m5<-summary(model5eje1)
print(paste("Modelo 5, errores: ", mean(abs(m5$residuals))))
#Promedios errores absolutos del modelo 6
m6<-summary(model2Box3eje1)
print(paste("Modelo 6, errores: ", mean(abs(m6$residuals))))
#Promedios errores absolutos del modelo 7
m7<-summary(model2Box2eje1)
print(paste("Modelo 7, errores: ", mean(abs(m7$residuals))))
#Promedios errores absolutos del modelo 8
m8<-summary(model2Box22eje1)
print(paste("Modelo 8, errores: ", mean(abs(m8$residuals))))
#resumenCumplimiento(8,modeleje1,model2eje1,model3eje1,model4eje1,model5eje1,model2Box3eje1,model2Box2eje1,model2Box22eje1)
```
Función para obtener el error absoluto promedio de un modelo 
```{r}
# Función para obtener el error absoluto promedio de un modelo
get_mean_absolute_error <- function(model) {
  #return(mean(abs(model$residuals)))
  residuals <- as.numeric(model$residuals)
  return(mean(abs(residuals)))
}
```

Conseguir el modelo con menor error absoluto medio

```{r}
# Crear un vector con los nombres de los modelos
model_names <- c("modeleje1", "model2eje1", "model3eje1", "model4eje1", "model5eje1", "model2Box3eje1", "model2Box2eje1", "model2Box22eje1")

errorModelos<-list(modeleje1,model2eje1,model3eje1,model4eje1,model5eje1,model2Box3eje1,model2Box2eje1,model2Box22eje1)

# Calcular los valores de error absoluto promedio para cada modelo en la lista errorModelos
mean_absolute_error_values <- sapply(errorModelos, get_mean_absolute_error)

# Obtener el índice del modelo con el menor valor de error absoluto promedio
min_index <- which.min(mean_absolute_error_values)

# Obtener el nombre del modelo con el menor valor de error absoluto promedio
best_model_name <- model_names[min_index]

# Obtener el valor del error absoluto promedio del mejor modelo
best_error <- mean_absolute_error_values[min_index]

# Imprimir el nombre del modelo y el valor del error absoluto promedio
cat("El modelo con el menor error absoluto promedio es", best_model_name, "con un error de", best_error, "\n")

# Imprimir el modelo con el menor valor de error absoluto promedio
cat("El modelo seria: \n")
print(errorModelos[min_index])
```

El modelo con menor error es el modelo 3 con un error 0.113185750482932 y almacenado en la variable model3eje1.

```{r}
get_mean_absolute_error(ajusterobP5)
```
Se observa un mayor error promedio de los errores en el modelo robusto que en el lineal.



## 6. Utilizar un método de selección de variables para proponer un modelo multivariado. Analizar el cumplimiento de los supuestos.

```{r}
require(leaps)
mejores_modelos <- regsubsets(precio ~ ., data = preciocasas, nvmax = 5) 
summary(mejores_modelos)
```

```{r}
summary(mejores_modelos)$adjr2
```
```{r}
# se identifica qué modelo tiene el valor máximo de R ajustado 
which.max(summary(mejores_modelos)$adjr2)
```
```{r}
library(ggplot2) 
p <- ggplot(data = data.frame(n_predictores = 1:5, R_ajustado = summary(mejores_modelos)$adjr2), aes(x = n_predictores, y = R_ajustado)) + 
  geom_line() + 
  geom_point() 
# Se identifica en rojo el máximo 
p <- p + geom_point(aes(x=n_predictores[which.max(summary(mejores_modelos)$adjr2)], y=R_ajustado[which.max(summary(mejores_modelos)$adjr2)]), colour = "red", size = 3) 
p <- p + scale_x_continuous(breaks = c(0:5)) + theme_bw() + 
  labs(title = "R2_ajustado vs número de predictores", x = "número predictores") 
p
```
```{r}
coef(object = mejores_modelos, id = 5)
```

```{r}
mejores_modelos_backward <- regsubsets(precio ~ ., data = preciocasas, nvmax = 5, method = "backward") 
# se identifica el valor máximo de R ajustado 
which.max(summary(mejores_modelos_backward)$adjr2)
```
```{r}
coef(object = mejores_modelos_backward, 5)
```
```{r}
mejores_modelos_forward <- regsubsets(precio ~ ., data = preciocasas, nvmax = 5, method = "forward") 
# se identifica el valor máximo de R ajustado 
which.max(summary(mejores_modelos_forward)$adjr2)
```

```{r}
coef(object = mejores_modelos_forward, 5)
```

Todas las combinaciones de modelos
```{r}
library(olsrr)
lm.fit1 <- lm(precio ~ ., data = preciocasas)
k <- ols_step_all_possible(lm.fit1)

# AIC: Akaike Information Criteria 
# SBIC: Sawa's Bayesian Information Criteria 
# SBC: Schwarz Bayesian Criteria 
# MSEP: Estimated error of prediction, assuming multivariate normality 
# FPE: Final Prediction Error 
# HSP: Hocking's Sp 
# APC: Amemiya Prediction Criteria

k # OJO: en RStudio se ven menos columnas en la salida
```
```{r}
plot(k)# el eje horizontal representa la cantidad de variables utilizadas en cada modelo.
```
```{r}
k_best <- ols_step_best_subset(lm.fit1)

# AIC: Akaike Information Criteria 
# SBIC: Sawa's Bayesian Information Criteria 
# SBC: Schwarz Bayesian Criteria 
# MSEP: Estimated error of prediction, assuming multivariate normality 
# FPE: Final Prediction Error 
# HSP: Hocking's Sp 
# APC: Amemiya Prediction Criteria

k_best
```
```{r}
plot(k_best)# el eje horizontal representa la cantidad de variables utilizadas en cada modelo.
```

```{r}
modeleje1P6= lm(precio ~ tamanio+caso+impuestos+estrena, data = preciocasas )
summary(modeleje1P6)
```
```{r}
#modelo lineal simple con la selección de las mejores variables
cumplimientoSupuestos(modeleje1P6)
```
```{r}
#modelo lineal simple transformado con la selección de las mejores variables
model2eje1P6= lm(log10(precio) ~ log10(tamanio+caso+impuestos+estrena), data = preciocasas )
summary(model2eje1P6)
```
```{r}
cumplimientoSupuestos(model2eje1P6)
```
```{r}
box_cox_resultP6 <- boxcox(precio ~ tamanio+caso+impuestos+estrena, lambda = -2:2, data = preciocasas)
```
```{r}
# Se encuentra el valor óptimo de lambda que maximiza el logaritmo de verosimilitud
best_box_coxP6 <- box_cox_result$x[which.max(box_cox_result$y)]
best_box_coxP6
```
```{r}
model2eje6P1 <- lm((precio)^(best_box_coxP6) ~ tamanio+caso+impuestos+estrena, data = preciocasas)

summary(model2eje6P1)
```
```{r}
cumplimientoSupuestos(model2eje6P1)
```

```{r}
model3eje6P1 <- lm((precio) ~ I((tamanio+caso+impuestos+estrena)^(best_box_coxP6)), data = preciocasas)

summary(model3eje6P1)
```
```{r}
cumplimientoSupuestos(model3eje6P1)
```
Se intenta con las variables de la selección de variables No. 43= impuestos dormitorios estrena tamanio

```{r}
model2eje1P6= lm(precio ~ impuestos+dormitorios+estrena+tamanio, data = preciocasas )
summary(model2eje1P6)
```
Se retira la variable dormitorios por no ser significativa
```{r}
model2eje1P6= lm(precio ~ impuestos+estrena+tamanio, data = preciocasas )
summary(model2eje1P6)
```
```{r}
cumplimientoSupuestos(model2eje1P6)
```
```{r}
box_cox_result2P6 <- boxcox(precio ~ impuestos + estrena + tamanio, lambda = -2:2, data = preciocasas)
```
```{r}
# Se encuentra el valor óptimo de lambda que maximiza el logaritmo de verosimilitud
best_box_cox2P6 <- box_cox_result2P6$x[which.max(box_cox_result$y)]
best_box_cox2P6
```

```{r}
model4eje6P1 <- lm((precio) ~ I((impuestos + estrena + tamanio)^(best_box_cox2P6)), data = preciocasas)

summary(model4eje6P1)
```
```{r}
cumplimientoSupuestos(model4eje6P1)
```
Ninguno de los modelos lineales con selección de variables cumplen los supuestos. Se comparte resumen de los modelos utilizados:
```{r}
resumenCumplimiento(6,modeleje1P6, model2eje1P6, model2eje6P1, model3eje6P1, model2eje1P6, model4eje6P1)
```


```{r}
#modelo lineal robusto con la seleccion de las mejores variables
ajusterobP6 <- lmrob(precio ~ tamanio+caso+impuestos+estrena, data = preciocasas)
summary(ajusterobP6)
```


```{r}
get_mean_absolute_error(ajusterobP6)
```
```{r}
evaluarErrores_modelos <- function(modelos) {
  # Crear un vector con los nombres de los modelos
  model_names <- names(modelos)
  
  # Calcular los valores de error absoluto promedio para cada modelo en la lista de modelos
  mean_absolute_error_values <- sapply(modelos, get_mean_absolute_error)
  
  # Obtener el índice del modelo con el menor valor de error absoluto promedio
  min_index <- which.min(mean_absolute_error_values)
  
  if (min_index > 0) {
    # Obtener el nombre del modelo con el menor valor de error absoluto promedio
    best_model_name <- model_names[min_index]
    
    # Obtener el valor del error absoluto promedio del mejor modelo
    best_error <- mean_absolute_error_values[min_index]
    
    # Imprimir el nombre del modelo y el valor del error absoluto promedio
    cat("El modelo con el menor error absoluto promedio es", best_model_name, "con un error de", best_error, "\n")
    
    # Imprimir el modelo con el menor valor de error absoluto promedio
    cat("El modelo sería:\n")
    print(modelos[[min_index]])
  } else {
    cat("No se pudo determinar el mejor modelo debido a un error en los nombres de los modelos.\n")
  }
}


```

```{r}
# Ejemplo de uso:
modelosP6 <- list(
  modeleje1P6 = modeleje1P6, 
  model2eje1P6 = model2eje1P6,
  model2eje6P1 = model2eje6P1,
  model3eje6P1 = model3eje6P1,
  model2eje1P6 = model2eje1P6,
  model4eje6P1 = model4eje6P1)

evaluarErrores_modelos(modelosP6)

```
Se observa que el mejor modelo lineal tiene un error absoluto promedio de 2.334749 a diferencia del modelo robusto con 32908.53. Como ninguno de los modelos presenta una representación de los datos si se sugiere usar GAMLSS, poruqe puede existir variables no linales que afectan los modelos utilizados hasta ahora.



## 7. Le parece adecuado un modelo GAMLSS en este caso? Justifique.

```{r}
mod_OLS <- gamlss( formula = precio ~ pb(tamanio)+caso+impuestos+estrena, family = NO, data = preciocasas, trace = FALSE)
summary(mod_OLS)
```


```{r}
plot(mod_OLS)
```
```{r}
cumplimientoSupuestos(mod_OLS)
```
```{r}
wp(mod_OLS)
```


```{r}

mod_GAMLSS <- gamlss(formula = precio ~ pb(tamanio)+caso+impuestos+estrena, sigma.formula = ~ pb(tamanio)+caso+impuestos+estrena, family = GA, data = preciocasas, trace = FALSE )
summary(mod_GAMLSS)
```

```{r}
plot(mod_GAMLSS)
```



```{r}
# Efecto individuales de los Predictores (GAMLSS)
term.plot(mod_GAMLSS, parameter = 'sigma',ask = FALSE, rug = TRUE)
```

```{r}
# Contribución de cada uno de los predictores (GAMLSS)
drop1(mod_GAMLSS, parameter = 'sigma', parallel = 'multicore', ncpus = 4)
```
```{r}
drop1(mod_GAMLSS, parameter = 'mu', parallel = 'multicore', ncpus = 4)
```

```{r}
mod_GAMLSS2 <- gamlss(formula = precio ~ pb(tamanio)+caso+impuestos+estrena, sigma.formula = ~ pb(tamanio), family = GA, data = preciocasas, trace = FALSE )
summary(mod_GAMLSS2)
```

```{r}
plot(mod_GAMLSS2)
```



```{r}
# Contribución de cada uno de los predictores (GAMLSS)
drop1(mod_GAMLSS2, parameter = 'sigma', parallel = 'multicore', ncpus = 4)
drop1(mod_GAMLSS2, parameter = 'mu', parallel = 'multicore', ncpus = 4)
```
```{r}
# Worm plot de los residuos modelo 1
wp(mod_GAMLSS, ylim.all = 0.5)
```
```{r}
# Worm plot de los residuos modelo 2
wp(mod_GAMLSS2, ylim.all = 0.5)
```
La inspección visual del wormplot de los dos modelos GAMLSS indica que estos modelos tienen los
residuos dentro del rango de variación aceptable.

```{r}
#Comparamos los modelos ajustados:
GAIC(mod_OLS,mod_GAMLSS, mod_GAMLSS2)
```

De acuerdo con el criterio GAIC, el modelo GAMLSS2 es el que mejor explica la relación con el precio utilizando los mismos predictores.

En tal sentido, si sería adecuado utilizar modelos GAMLSS debido a que con estos se puede analizar conjuntos de datos que tengan comportamientos no lineales y exista presencia de heterocedasticidad.

## 8. Resuma sus conclusiones.

En general se puede concluir que del conjunto de datos preciocasas, la variable precio se puede predecir en función de la variable tamanio, esta variable tiene un comportamiento no lineal y la implementación de modelos GAMLSS permite una mejor interpretación del modelo.  


# <span style="color:darkred">Ejercicio 2 </span>

Se desea saber si la dosis de ácido ascórbico y el tipo de bebida en la cual se lo administró a ciertos animales de
laboratorio logró mayor desarrollo de los dientes en los mismo. Se utilizaron 60 replicaciones del experimento y se tienen grupos balanceados. La variable respuesta de interés es la longitud de los dientes frontales(len). Los resultados están en el archivo odonto.csv Se pide analizar, analítica y gráficamente, si:

```{r}
odonto<-read.csv("C:/Users/Josvaldes/Documents/Maestria/Austral/1ano/regresionAvanzada/TPRegresion/TPRegresion/examen/prueba/odonto.csv")
odonto
```


## 1. Existen diferencias estadísticamente significativas respecto de las dosis administradas?

Se Compara los resultados según los niveles de ambas categorías.

```{r}
library(ggplot2) 
library(gridExtra)

# Se convierte la variables dose en factor
odonto$dose<-factor(odonto$dose)
odonto$supp<-factor(odonto$supp)

p1 <- ggplot(data = odonto, mapping = aes(x = dose, y = len)) + geom_boxplot() + 
  theme_bw() 
p2 <- ggplot(data = odonto, mapping = aes(x = supp, y = len)) + geom_boxplot() + 
  theme_bw() 
p3 <- ggplot(data = odonto, mapping = aes(x = dose, y = len, colour = supp)) + 
  geom_boxplot() + theme_bw() 
grid.arrange(p1, p2,p3, ncol = 2)

```
Parece existir interacción de las variables y diferencia de medias entre las categorías de la variable dose.

Análisis de interacciones

```{r}
interaction.plot(trace.factor = odonto$supp, x.factor = odonto$dose, response = odonto$len, fun = "mean", legend = TRUE, col = 2:3, type = "b")
```
Se observa que parece que existe interacción entre las variables dose y supp.

```{r}
interaction.plot(trace.factor = odonto$dose, x.factor = odonto$supp, response = odonto$len, fun = "mean", legend = TRUE, col = 2:3, type = "b")
```
Para el caso de validar la interacción entre las variables trazando desde la variable dose no se logra ver interacción.

```{r}
ggplot(data = odonto, aes(x = dose, y = len, colour = supp, group = supp)) + 
  stat_summary(fun = mean, geom = "point") + stat_summary(fun.y = mean, geom = "line") + 
  labs(y = "mean (resultado)") + theme_bw()
```
Se repite la primera grafica de interacción con otro comando y se obtiene una gráfica parecida, se concluye que existe una interacción entre las variables categóricas dose y supp.

```{r}
anova_2vias <- aov(formula = len ~ dose*supp, data = odonto) 
summary(anova_2vias)
```
En base a los resultados:

El factor dose muestra un efecto significativo en la variable respuesta (len) debido a que el valor de p es extremadamente pequeño (< 2e-16). Esto indica que la dosis tiene un impacto estadísticamente significativo en len.

El factor supp también tiene un efecto significativo en len con un valor de p de 0.000231. Esto sugiere que el tipo de suplemento tiene un impacto significativo en la variable respuesta.

Además, la interacción entre dose y supp también es significativa con un valor de p de 0.021860. Esto indica que el efecto de la dosis sobre la variable respuesta depende del tipo de suplemento utilizado.

En general, estos resultados sugieren que tanto la dosis como el tipo de suplemento tienen un impacto significativo en la variable respuesta len, y que la interacción entre ambos factores también es relevante.

```{r}
library(lsr)
etaSquared(anova_2vias)
```
Para el factor dose, el coeficiente eta cuadrado (eta.sq) es 0.70286419, lo que indica que el 70.29% de la variabilidad total de la variable respuesta (len) se puede explicar por la variabilidad en el factor dose. Esto sugiere que dose tiene un efecto muy grande y explica una cantidad significativa de la variabilidad observada en la variable respuesta.

El coeficiente eta cuadrado parcial (eta.sq.part) para el factor dose es 0.7731092. Este valor indica la proporción de la variabilidad única explicada por dose, es decir, el efecto exclusivo de dose en la variable respuesta después de considerar otros factores en el modelo. En este caso, el 77.31% de la variabilidad única en len se puede atribuir al factor dose.

Para el factor supp, el coeficiente eta cuadrado (eta.sq) es 0.05948365, lo que indica que el 5.95% de la variabilidad total en len se puede explicar por la variabilidad en el factor supp. Esto sugiere que supp tiene un efecto más pequeño en comparación con dose en la explicación de la variabilidad en la variable respuesta.

El coeficiente eta cuadrado parcial (eta.sq.part) para el factor supp es 0.2238254. Esto indica que el 22.38% de la variabilidad única en len se puede atribuir al factor supp después de tener en cuenta otros factores en el modelo.

Para la interacción entre dose y supp (dose:supp), el coeficiente eta cuadrado (eta.sq) es 0.03137672, lo que indica que el 3.14% de la variabilidad total en len se puede explicar por la variabilidad en la interacción. Este valor sugiere que la interacción entre dose y supp también contribuye de manera significativa a la variabilidad en la variable respuesta.

Finalmente el coeficiente eta cuadrado parcial (eta.sq.part) de la interacción entre dose y supp es 0.1320279. Esto indica que el 13.20% de la variabilidad única en len se puede atribuir a la interacción entre dose y supp después de considerar otros factores en el modelo.

En resumen, los coeficientes eta cuadrado indican la proporción de variabilidad explicada por cada factor y su interacción en la variable respuesta, mientras que los coeficientes eta cuadrado parcial reflejan la proporción de variabilidad única explicada por cada factor después de considerar otros factores en el modelo. En este caso, dose tiene el mayor efecto en len, seguido por supp y la interacción entre ambos factores.

```{r}
par(mfrow = c(2,2)) 
plot(anova_2vias)
```
El resumen de los gráficos del modelo muestra al parecer el cumplimiento de los supuestos. Estos son analizados en el sub numeral 4.

Con relación a la pregunta incial, sí existen diferencias estadísticamente significativas respecto de las dosis administradas. Esto se puede deducir de la salida del análisis de varianza de dos vías (ANOVA de dos vías):

El factor dose muestra un efecto significativo en la variable respuesta (len) debido a que el valor de p es extremadamente pequeño (< 2e-16). Esto indica que la dosis tiene un impacto estadísticamente significativo en len.
El valor de p extremadamente pequeño (< 2e-16) indica que la probabilidad de obtener una diferencia tan grande o mayor entre las medias de las dosis por pura casualidad es extremadamente baja. Por lo tanto, podemos concluir que hay diferencias estadísticamente significativas en la variable respuesta (len) entre las diferentes dosis administradas.

En resumen, el análisis de varianza indica que existe una diferencia estadísticamente significativa en la variable respuesta (len) en función de las dosis administradas.

## 2. Existen diferencias estadísticamente singificativas respecto del tipo de vehículo de administración?

Sí, existen diferencias estadísticamente significativas respecto del tipo de vehículo de administración. Esto se puede deducir de la salida del análisis de varianza de dos vías (ANOVA de dos vías):

El factor supp también tiene un efecto significativo en len con un valor de p de 0.000231. Esto sugiere que el tipo de vehículo de administración tiene un impacto significativo en la variable respuesta.
El valor de p extremadamente pequeño (0.000231) indica que la probabilidad de obtener una diferencia tan grande o mayor entre las medias de los diferentes tipos de vehículo de administración por pura casualidad es extremadamente baja. Por lo tanto, podemos concluir que hay diferencias estadísticamente significativas en la variable respuesta (len) entre los diferentes tipos de vehículo de administración.

En resumen, el análisis de varianza indica que existe una diferencia estadísticamente significativa en la variable respuesta (len) en función del tipo de vehículo de administración.

## 3. La interacción entre estas variables es significativa?

Sí, la interacción entre las variables dose (dosis administrada) y supp (tipo de vehículo de administración) es significativa. Esto se puede deducir de la salida del análisis de varianza de dos vías (ANOVA de dos vías):

La interacción dose:supp también es significativa con un valor de p de 0.021860. Esto indica que el efecto de la dosis sobre la variable respuesta depende del tipo de vehículo de administración utilizado.

El valor de p (0.021860) por debajo de un umbral de significancia (como 0.05) indica que la probabilidad de obtener una interacción tan grande o mayor entre las dos variables por pura casualidad es baja. Por lo tanto, podemos concluir que hay una interacción estadísticamente significativa entre las variables dose y supp en relación con la variable respuesta (len).

En resumen, el análisis de varianza indica que la interacción entre las variables dose y supp es estadísticamente significativa. Esto implica que el efecto de la dosis sobre la variable respuesta (len) difiere según el tipo de vehículo de administración utilizado.

## 4. Se satisfacen los supuestos del modelo?

Se implementa la función de cumplimiento de modelos definida con anterioridad
```{r}
cumplimientoSupuestos(anova_2vias)
```
Se observa que, si se satisfacen los supuestos del modelo, siendo los residuos normales, homocedasticos e independientes.


## 5. Puede realizar una recomendación?

Basado en los resultados del análisis de varianza de dos vías, donde se encontraron diferencias estadísticamente significativas tanto para la dosis administrada como para el tipo de vehículo de administración, así como una interacción significativa entre ambas variables, se podria recomendar lo siguiente:

Dado que tanto la dosis administrada como el tipo de vehículo de administración tienen un impacto significativo en la variable respuesta (len), es importante considerar estas variables al tomar decisiones relacionadas con el tratamiento o intervención en el contexto del estudio.

Recomendaría analizar más a fondo las relaciones entre la dosis administrada y el tipo de vehículo de administración en relación con los efectos observados en len. Esto podría implicar realizar análisis adicionales o realizar comparaciones más detalladas entre los diferentes niveles de dosis y los diferentes tipos de vehículo de administración.

Además, dado que se encontró una interacción significativa entre la dosis y el tipo de vehículo de administración, se sugiere investigar la naturaleza de esta interacción y cómo afecta la variable respuesta. Puede ser útil realizar análisis de subgrupos o realizar comparaciones específicas entre los diferentes niveles de dosis dentro de cada tipo de vehículo de administración.

En general, al considerar las diferencias significativas encontradas en el estudio, es importante tener en cuenta tanto la dosis administrada como el tipo de vehículo de administración al diseñar estrategias de tratamiento o intervención y al interpretar los resultados obtenidos.

# <span style="color:darkred">Ejercicio 3 </span>

En el archivo morosos.xlsx se encuentran los registros de 10 mil clientes de un banco para los cuales se relevaron
las siguientes variables:
• mora: si está en mora con el saldo de su tarjeta de crédito.
• estudiantes: si es estudiante o no.
• balance: el saldo al 31/12 próximo pasado.
• ingreso: ingreso mensual medio del cliente.

```{r}
morosos<-read_excel("C:/Users/Josvaldes/Documents/Maestria/Austral/1ano/regresionAvanzada/TPRegresion/TPRegresion/examen/prueba/morosos.xlsx")
morosos
```


Se desea modelar la probabilidad de mora de un cliente en función de las variables disponibles en la base.
Se pide:


# 1. Ajustar un modelo logístico para predecir la probabilidad de incurrir en mora.

```{r}

# Crear una nueva variable binaria para representar 'mora'
morosos$bin_mora <- ifelse(morosos$mora == "Yes", 1, 0)

# Ajustar el modelo logístico con la nueva variable binaria
modelo_logistico <- glm(bin_mora ~ ingreso, data = morosos, family = "binomial")

# Realizar el análisis del modelo
summary(modelo_logistico)

```
Intercepto: El valor estimado del intercepto es de -3.094, lo cual indica el logaritmo de la razón de probabilidad de que la variable respuesta sea igual a 1 cuando la variable ingreso es igual a 0. Un valor negativo indica que la probabilidad de que ocurra el evento es menor.

Coeficiente de ingreso: El valor estimado del coeficiente de ingreso es de -8.353e-06. Este coeficiente representa el cambio en el logaritmo de la razón de probabilidad de la variable respuesta por cada unidad de cambio en la variable ingreso. En este caso, un incremento en ingreso se asocia con una disminución en la probabilidad de que ocurra el evento.

Significancia estadística: El coeficiente de ingreso es significativamente diferente de cero con un valor p de 0.0471. Esto indica que existe evidencia estadística para sugerir que la variable ingreso tiene un efecto significativo en la variable respuesta bin_mora.

Deviance residuals: Los residuos de deviance son medidas de ajuste del modelo y cuantifican la discrepancia entre las respuestas observadas y las predichas por el modelo. Los valores oscilan entre -0.2968 y 2.7111, y se espera que estén cerca de cero.

AIC: El valor de AIC (Akaike Information Criterion) del modelo es de 2920.7. El AIC es una medida de la calidad del ajuste del modelo, y un valor más bajo indica un mejor ajuste.

En resumen, el modelo logístico muestra que la variable ingreso tiene un efecto estadísticamente significativo en la probabilidad de que ocurra el evento representado por la variable bin_mora. Sin embargo, se observa que el coeficiente estimado para ingreso es muy pequeño, lo que indica una asociación débil entre la variable predictora y la variable respuesta.

```{r}
#validación de las demas variables
# Ajustar el modelo logístico con la nueva variable binaria
modelo_logistico2 <- glm(bin_mora ~ estudiante, data = morosos, family = "binomial")

# Realizar el análisis del modelo
summary(modelo_logistico2)
```
Se observa que la variable estudiante es significativa.

```{r}
#validación de las demas variables
# Ajustar el modelo logístico con la nueva variable binaria
modelo_logistico3 <- glm(bin_mora ~ balance, data = morosos, family = "binomial")

# Realizar el análisis del modelo
summary(modelo_logistico3)
```
La variable balance tambien es significativa.

```{r}
#validación dcon todas variables
# Ajustar el modelo logístico con la nueva variable binaria
modelo_logistico4 <- glm(bin_mora ~ ingreso+estudiante+balance, data = morosos, family = "binomial")

# Realizar el análisis del modelo
summary(modelo_logistico4)
```
Con todas la variables se observa que se reduce el AIC y la variable ingreso deja de ser signiticativa.

```{r}
library(lmtest)
#Prueba de verosimilitud
lrtest<-lrtest(modelo_logistico, modelo_logistico4)
lrtest
```
El test de razón de verosimilitud sugiere que el modelo 2 (bin_mora ~ ingreso + estudiante + balance) proporciona un ajuste significativamente mejor que el modelo 1 (bin_mora ~ ingreso), lo que implica que la inclusión de las variables estudiante y balance mejora la capacidad de predicción de la variable respuesta bin_mora.

```{r}
#Validación del AIC
modelo_logistico$aic
modelo_logistico2$aic
modelo_logistico3$aic
modelo_logistico4$aic
```
Por el critero de AIC se observa que el modelo 4 es el que mejor ajusta.

```{r}
# Validación de un quinto modelo sin la variable ingreso
# Ajustar el modelo logístico con la nueva variable binaria
modelo_logistico5 <- glm(bin_mora ~ estudiante+balance, data = morosos, family = "binomial")

# Realizar el análisis del modelo
summary(modelo_logistico5)
```
```{r}
lrtest(modelo_logistico4, modelo_logistico5)
```
El test de razón de verosimilitud sugiere que no hay evidencia suficiente para concluir que el modelo 2 (bin_mora ~ estudiante + balance) proporciona un ajuste significativamente mejor que el modelo 1 (bin_mora ~ ingreso + estudiante + balance). Por lo tanto, no se justifica eliminar la variable ingreso del modelo.

# 2. Evaluar la calidad de ajuste del modelo con al menos dos criterios distintos.

Para evaluar la calidad de ajuste del modelo logístico, se pueden utilizar varios criterios. A continuación, se presentan dos criterios comunmente utilizados:

Deviance: La deviance es una medida de la discrepancia entre el modelo ajustado y los datos observados. Un valor de deviance más bajo indica un mejor ajuste del modelo. Se puede comparar la deviance del modelo ajustado con la deviance del modelo nulo (modelo sin covariables) para evaluar la mejora en el ajuste. Si la deviance del modelo ajustado es significativamente más baja que la del modelo nulo, indica que el modelo tiene un buen ajuste.

```{r}
#Validación del Deviance
modelo_logistico$deviance
modelo_logistico2$deviance
modelo_logistico3$deviance
modelo_logistico4$deviance

```
Se observa que el modelo elegido por p-valor sigue siendo elegido por menor deviance, modelo_logistico4.

AIC (Akaike Information Criterion): El criterio de información de Akaike es una medida de la calidad del ajuste del modelo que tiene en cuenta la complejidad del modelo. Se calcula utilizando la deviance del modelo y el número de parámetros del modelo. Un valor de AIC más bajo indica un mejor ajuste del modelo. Al comparar diferentes modelos, el modelo con un AIC más bajo se considera preferido.

Este se desarrollo en el punto anterior y eligio al modelo 4.
# 3. Interpretar los coeficientes del modelo elegido.

```{r}
modelo_logistico4$coefficients
```
Coeficiente de Intercepto: -1.086905e+01
Este coeficiente representa el efecto del término constante en el modelo cuando todas las variables predictoras son cero. En este caso, el intercepto indica el logaritmo de la odds (relación de probabilidades) de que el evento de interés ocurra cuando todas las variables predictoras son cero.

Coeficiente de ingreso: 3.033450e-06
Este coeficiente indica cómo cambia la log-odds (logaritmo de la odds) del evento de interés por cada unidad de cambio en la variable "ingreso". Dado que el coeficiente es positivo, un incremento en el valor de "ingreso" se asociaría con un aumento en la log-odds del evento de interés.

Coeficiente de estudianteYes: -6.467758e-01
Este coeficiente representa el efecto de la variable categórica "estudiante" cuando su valor es "Yes", en comparación con cuando su valor es "No". Un coeficiente negativo indica que ser estudiante está asociado con una disminución en la log-odds del evento de interés en comparación con no ser estudiante.

Coeficiente de balance: 5.736505e-03
Este coeficiente indica cómo cambia la log-odds del evento de interés por cada unidad de cambio en la variable "balance". Dado que el coeficiente es positivo, un aumento en el valor de "balance" se asocia con un aumento en la log-odds del evento de interés.

Es importante tener en cuenta que los coeficientes están en la escala logarítmica debido a la naturaleza del modelo logístico. Para interpretar los efectos en términos de probabilidades, se pueden aplicar transformaciones, como la exponenciación de los coeficientes para obtener odds ratios o la aplicación de la función de enlace inversa (por ejemplo, la función logística) para obtener probabilidades directamente.

# 4. Evaluar la calidad de clasificación y compararlo con otro método de clasificación.


```{r}
library(ResourceSelection)
hoslem.test(morosos$bin_mora, fitted(modelo_logistico4))
```
El resultado del test de bondad de ajuste de Hosmer-Lemeshow indica que no hay evidencia suficiente para rechazar la hipótesis nula de que el modelo se ajusta bien a los datos. El valor de p obtenido es 0.8846, lo que indica que no hay una diferencia significativa entre los valores observados y los valores esperados según el modelo. En otras palabras, el modelo parece ajustarse adecuadamente a los datos según esta prueba específica de bondad de ajuste.

Matriz de confusión

```{r}
library(vcd) 
predicciones <- ifelse(test = modelo_logistico4$fitted.values > 0.5, yes = 1, no = 0) 
matriz_confusion <- table(morosos$bin_mora, predicciones, dnn = c("observaciones", "predicciones")) 
matriz_confusion
```

```{r}
mosaic(matriz_confusion, shade = T, colorize = T, gp = gpar(fill = matrix(c("green3", "red2", "red2", "green3"), 2, 2)))
```
La matriz de confusión muestra un problema de calificación de clase 1

Separación en muestra de entrenamiento y test para obtener métricas de test

```{r}
library(pROC)
set.seed(20231)
entrenamiento<-sample(1:500,70)

validacion<-c(1:500)[-entrenamiento]

morosos_train<-morosos[entrenamiento,]
morosos_test<-morosos[validacion,]
bin_mora_train<-morosos$bin_mora[entrenamiento]
table(bin_mora_train)
```
```{r}
bin_mora_test<-morosos$bin_mora[validacion]
table(bin_mora_test)
```

```{r}
morosos_new<-data.frame(morosos_test)
morosos_new$origen<-bin_mora_test

# Se obtienen las probabilidades predichas para cada clase 
predicciones <- predict(object = modelo_logistico4, newdata = morosos_new, type = "response") 

curva_roc <- roc(response = morosos_new$origen, predictor = predicciones, levels = c(0, 1), direction = "<") 

```


```{r}
curva_roc
```

```{r}
# Gráfico de la curva 
#plot(curva_roc)
plot(curva_roc,col="red",lwd=2,main="ROC test")
legend("bottomright",legend=paste("AUC=",round(auc(curva_roc),4)))
```
Se observa una curva ROC que explica el 96,62% de la variable respuesta, muestra ser un buen modelo para detectar a los morosos.

```{r}
# otra forma
#install.packages("ROCR", repos = "http://cran.us.r-project.org", dependencies = TRUE)
library(ROCR)

real <- morosos_new$origen

predic <-prediction(predicciones,real)
perf <-  performance(predic, "tpr","fpr")

plot(perf,
     main = "Curva ROC",
     xlab="Tasa de falsos positivos", 
     ylab="Tasa de verdaderos positivos")
abline(a=0,b=1,col="blue",lty=2)
grid()
auc <- as.numeric(performance(predic,"auc")@y.values)
legend("bottomright",legend=paste(" AUC =",round(auc,4)))
```

funcion curva ROC
```{r}
curvaROC <- function(muestra,porcentaje,dataset,x,modelo){
 #muestra: numero de muestra de la población
 #porcentaje: Porcentaje de datos de la muestra para el test
 #dataset: Conjunto de datos utilizado
 #x: Variable predictora
 #modelo: Modelo utilizado para hacer el ajuste.
  
  set.seed(20231)
  

  entrenamiento<-sample(1:muestra,porcentaje)

  validacion<-c(1:muestra)[-entrenamiento]
  
  
  # Crear una nueva variable binaria para representar 'x'
  dataset$bin_x <- ifelse(x == "Yes", 1, 0)

  dataset_train<-dataset[entrenamiento,]
  dataset_test<-dataset[validacion,]
  bin_x_train<-dataset$bin_x[entrenamiento]
  table(bin_x_train)
  
  bin_x_test<-dataset$bin_x[validacion]
  dataset_new<-data.frame(dataset_test)
  dataset_new$origen<-bin_x_test
  
  real <- dataset_new$origen

  
  dataset_new<-data.frame(dataset_test)
  dataset_new$origen<-bin_x_test
  # Se obtienen las probabilidades predichas para cada clase 
  predicciones <- predict(object = modelo, newdata = dataset_new, type = "response") 
  

  predic <-prediction(predicciones,real)
  perf <-  performance(predic, "tpr","fpr")

  g=plot(perf,
     main = "Curva ROC",
     xlab="Tasa de falsos positivos", 
     ylab="Tasa de verdaderos positivos")
  abline(a=0,b=1,col="blue",lty=2)
  grid()
  auc <- as.numeric(performance(predic,"auc")@y.values)
  legend("bottomright",legend=paste(" AUC =",round(auc,4)))
  return(g)
}
```



```{r}
mora=morosos$mora
curvaROC(500,90,morosos,mora,modelo_logistico)
curvaROC(500,90,morosos,mora,modelo_logistico2)
curvaROC(500,90,morosos,mora,modelo_logistico3)
curvaROC(500,90,morosos,mora,modelo_logistico4)
curvaROC(500,90,morosos,mora,modelo_logistico5)
```

Precision : TP / (TP+FP)

Recall : TP / (TP+FN)

F1 Score : (2 * Precision * Recall) / (Precision+Recall)

```{r}

actual_values<-bin_mora_test
predict_value<-predicciones
table(ACTUAL=actual_values,PREDICTED=predict_value>0.5) # asumimos umbral de 0.5


```
```{r}
pred<-predict_value>0.5
TP<-length(actual_values[(actual_values==1)&(pred==1)])#15
TN<-length(actual_values[(actual_values==0)&(pred==0)])#12
FP<-length(actual_values[(actual_values==0)&(pred==1)])#1
FN<-length(actual_values[(actual_values==1)&(pred==0)])#2

precision<-TP/(TP+FP)
precision
```
```{r}
recall<-TP/(TP+FN)
recall
```

```{r}
f1_score<-(2*precision*recall)/(precision+recall) 
f1_score
```

