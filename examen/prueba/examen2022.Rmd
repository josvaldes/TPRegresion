---
title: "Examen año 2022"
author: "Jose Valdes"
date: "2023-07-12"
output:
  html_document:
    toc: yes
    code_folding: show
    toc_float: yes
    df_print: paged
    theme: united
    code_download: yes
  pdf_document:
    toc: yes
    toc_depth: '5'
  word_document:
    toc: yes
    toc_depth: '5'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
#limpio la memoria
rm( list= ls(all.names= TRUE) )  #remove all objects
gc( full= TRUE )                 #garbage collection
```
Se realiza validación de la instalación de los paquetes necesarios para ejecutar el script

```{r}
# Bibliotecas a cargar

check_packages <- function(packages) {
  if (all(packages %in% rownames(installed.packages()))) {
    TRUE
  } else{
    cat(
      "Instalar los siguientes packages antes de ejecutar el presente script\n",
      packages[!(packages %in% rownames(installed.packages()))],
      "\n"
    )
  }
}
packages_needed <- c("readxl","ggplot2","MVN","gridExtra","aod","MASS","carData","car","robustbase","leaps","olsrr","gamlss","lsr","ggpubr","lmtest")

# Se llama a la funcion check_packages
check_packages(packages_needed)


library(readxl)
library(ggplot2)
library(MVN)
library(gridExtra)
library(aod)
library(MASS)
library(carData)
library(car)
library(robustbase)
library(leaps)
library(olsrr)
library(gamlss)
library(lsr)
library(ggpubr)
library(lmtest)

```


# <span style="color:darkred">Ejercicio 1 </span>
En el archivo preciocasas.xlsx se han registrado respecto de 100 viviendas las siguientes variables:
• impuestos: valor de impuesto anual de la vivienda.
• dormitorios cantidad de ambientes de la vivienda.
• banios: cantidad de baños del inmueble.
• estrena: si es a estrenar.
• precio: valor del alquiler de la vivienda
• tamanio: superficie total de la vivienda.

```{r}
library(readxl)
preciocasas<-read_excel("C:/Users/Josvaldes/Documents/Maestria/Austral/1ano/regresionAvanzada/TPRegresion/TPRegresion/examen/prueba/preciocasas.xlsx")
preciocasas
```

Se observa la distrubución  a través de un grafico:

Diagrama de dispersión
```{r}
library(ggplot2)
#Diagrama de dispersión precio en función del tamanio
dd1=ggplot(preciocasas, aes(tamanio, precio)) + 
  geom_point() + theme_minimal() + labs(title = "Diagrama de dispersi\u00F3n precio vs tamanio")
dd1
```

Por la distribución de los datos se creeria que se podria realizar un ajuste lineal.

## 1. Construir un modelo lineal simple para explicar el precio en función de la superficie y evaluar la bondad del ajuste.

```{r} 
modeleje1= lm(precio ~ tamanio, data = preciocasas )
summary(modeleje1)
```
- El intercepto (constante) tiene una estimación de -50926.255 y es significativamente diferente de cero, lo que indica que hay un valor base en el precio que no depende del tamaño.
- La variable "tamanio" tiene una estimación de 126.594, lo que significa que por cada unidad de aumento en el tamaño, se espera un aumento de 126.594 en el precio.
- Ambos coeficientes (intercepto y tamanio) son estadísticamente significativos, ya que los valores p son muy pequeños (<0.001).
- El coeficiente de determinación (R-cuadrado) es 0.6952, lo que indica que aproximadamente el 69.52% de la variabilidad en el precio se explica por el modelo.
- El error estándar residual es 56190, lo que indica la dispersión promedio de los residuos alrededor de la línea de regresión.
- El valor F es 223.5 con un valor p muy pequeño (<2.2e-16), lo que indica que el modelo es estadísticamente significativo y hay una relación lineal entre el tamaño y el precio.


## 2. Realizar un análisis diagnóstico y de puntos influyentes e indicar si el modelo es adecuado.

Análisis diagnóstico
-Normalidad
```{r}
shapiro.test(preciocasas$tamanio)
```
Se rechaza normalidad de la variable tamanio.

```{r}
shapiro.test(preciocasas$precio)
```

Análisis de normalidad multivariada - Test de Henze Zirkler

```{r}
#Analizamos normalidad bivariada
library(MVN)
#Usamos Test Henze-Zirkler para evaluar normalidad multivariada (bivariada en este caso)
respuesta_testHZ<-mvn(preciocasas , mvnTest = "hz")
respuesta_testHZ
```
Se realiza el test de correlación de Spearman debio a que no se observa que las variables sean normales entre ellas.

```{r}
cor.test(preciocasas$precio,preciocasas$tamanio, method="spearman", exact = FALSE)
```
Se rechaza la hipotesis nula de que no hay correlacion entre las variables, en tal sentido, se evidencia correlación entre las variables. Con relación a las variables análizadas precio y tamanio, estas corresponde a una correlacion positiva de alrededor del 74.17 %. A continuacion se presente un correlograma para un analisis mas amplio del conjunto de datos:

```{r}
library(corrplot)
corrplot(cor(preciocasas,method="s"))
```


normalidad de los residuos del modelo
```{r}
shapiro.test(modeleje1$residuals)
```
Tampoco los residuos del modelo son normales.


- homocedastisidad

```{r}
preciocasas2<-preciocasas
preciocasas2$prediccion <- modeleje1$fitted.values 
preciocasas2$residuos <- modeleje1$residuals

ggplot(data = preciocasas2, aes(x = prediccion, y = residuos)) + 
  geom_point(aes(color = residuos)) + 
  scale_color_gradient2(low = "blue3", mid = "grey", high = "red") + 
  geom_hline(yintercept = 0) + geom_segment(aes(xend = prediccion, yend = 0), alpha = 0.2) + 
  labs(title = "Distribución de los residuos", x = "predicción modelo", y = "residuo") + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none")
```
Paraciera tener estructura, los residuos se entienden que no son homocedasticos.

```{r}
library(lmtest) #carga la librería lmtest
bptest(modeleje1)
```
Se corrobora rechazo de la hipotesis nula de homecedastidad, los residuos son heterosedasticos.

- Independencia

```{r}
dwtest(modeleje1)
```
Se rechaza Ho, la hipótesis alternativa indica que existe una autocorrelación positiva mayor que cero en los residuos del modelo. Esto significa que hay evidencia de autocorrelación en los residuos del modelo, lo que sugiere que las observaciones están correlacionadas entre sí en cierta medida.



Outliers, puntos influyentes, y de alto leverage


Análisis de residuos y residuos estudentizados

```{r}
par(mfrow=c(2,2))
plot(modeleje1)
```

```{r}
summary(influence.measures(model = modeleje1))
```
```{r}

which(dfbetas(modeleje1)[,2]>1)
```
```{r}
n<-length(preciocasas$precio)
p<-length(modeleje1$coefficients)
which(dffits(modeleje1)>2 * sqrt(p / n))
```
Otros puntos influyentes

```{r}
library(car)
influencePlot(model = modeleje1)
```

```{r}
influenceIndexPlot(modeleje1, vars='Bonf', las=1,col='green')
```

```{r}
outlierTest(modeleje1)
```


Se confirma la observación No. 64 es un punto influyent y outlier. La Observación 6 y 9 son de que resaltan entre los demas puntos influyentes.

El modelo no es adecuado porque no cumple los supuestos, aunque el R cuadro explica un 69,21 % de la variable respuesta no cumplen los supuestos de normalidad, varianza constante e independencia. Se debe validar una transformación.


## 3. Realizar una transformaci´on de la variable respuesta para lograr normalidad en la distribuci´on de los residuos. Indicar si el modelo con esta transformaci´on resulta adecuado.

```{r}
library(MASS)
box_cox_result <- boxcox(precio ~ tamanio, lambda = -2:2, data = preciocasas)
```
```{r}
# Se encuentra el valor óptimo de lambda que maximiza el logaritmo de verosimilitud
best_box_cox <- box_cox_result$x[which.max(box_cox_result$y)]

# Se ajusta un modelo de regresión lineal utilizando la variable dependiente "precio" elevada a la potencia óptima de lambda (best_box_cox) como la variable de respuesta y la variable independiente "tamanio".
model2eje1 <- lm((precio)^(best_box_cox) ~ tamanio, data = preciocasas)

summary(model2eje1)
```
En el modelo transformado se sigue observando que en general es significativo tanto de forma global como individual, el R cuadro baja un poco con relación al primer modelo pero aún sigue siendo representativo, 65.66%.

Se realiza analisis de los supuestos

**Normalidad**

```{r}
shapiro.test(model2eje1$residuals)
```
Se rechaza normalidad, pero se observa que se acerca a la zona de no rechazo.

**Homocedastisidad**

```{r}
preciocasas3<-preciocasas
preciocasas3$prediccion <- model2eje1$fitted.values 
preciocasas3$residuos <- model2eje1$residuals

ggplot(data = preciocasas3, aes(x = prediccion, y = residuos)) + 
  geom_point(aes(color = residuos)) + 
  scale_color_gradient2(low = "blue3", mid = "grey", high = "red") + 
  geom_hline(yintercept = 0) + geom_segment(aes(xend = prediccion, yend = 0), alpha = 0.2) + 
  labs(title = "Distribución de los residuos", x = "predicción modelo", y = "residuo") + 
  theme_bw() + 
  theme(plot.title = element_text(hjust = 0.5), legend.position = "none")
```

```{r}
bptest(model2eje1)
```
Los residuos son homocedasticos, con relación al modelo anterior se observa que se mejora para ser residuos homocedasticos.

**Independencia**

```{r}
dwtest(model2eje1)
```
Se sigue rechazando Ho, existe autocorrelacion de los residuos del modelo.


Se intenta con un tercer modelo

```{r}
# Basado que el lamda optimo dio best_box_cox = 0.3030303, se intenta aproximandolo a cero
model3eje1 <- lm(log10(precio) ~ tamanio, data = preciocasas)
summary(model3eje1)
```

**Normalidad**
```{r}
shapiro.test(model3eje1$residuals)
```

Sigue sin cumplir normalidad

```{r}
model4eje1 <- lm((precio) ~ log10(tamanio), data = preciocasas)
summary(model4eje1)
```
**Normalidad**
```{r}
shapiro.test(model4eje1$residuals)
```
Sigue sin cumplir normalidad

```{r}
model5eje1 <- lm(log10(precio) ~ log10(tamanio), data = preciocasas)
summary(model5eje1)
```
**Normalidad**
```{r}
shapiro.test(model5eje1$residuals)
```
Se cumple el supuesto de normalidad, esto muy cerca de la zona de rechazo.


**Homocedasticidad**
```{r}
bptest(model5eje1)
```
Se cumple el supuesto de homocedastisidad de los residuos.


**Independencia**
```{r}
dwtest(model5eje1)
```
Se cumple independencia.

El modelo 5 cumple los supuestos y se podria utilizar para explicar la variable precio en funcion de tamanio.


```{r}
#Funcion de cumplimientos de supuestos
Respuesta=0
cumplimientoSupuestos <- function(modeloLineal) {
  #Supuesto de normalidad
  Normalidad=shapiro.test(modeloLineal$residuals)
    if (Normalidad$p.value>0.05){
      Respuesta[1]="Normal"
    } else {
      Respuesta[1]="No es normal"
    }
  #Supuesto de homocedastisidad
  homocedastisidad=bptest(modeloLineal)
    if (Normalidad$p.value>0.05){
      Respuesta[2]="homocedastico"
    }else {
      Respuesta[2]="No es homocedastico"
    }
  #Supuesto de independencia
  independencia=dwtest(modeloLineal)
    if (Normalidad$p.value>0.05){
      Respuesta[3]="independiente"
    }else {
      Respuesta[3]="No es independiente"
    }
  
  return(Respuesta)
  
}

#cumplimientoSupuestos(model5eje1)
```
Se resume a continuación los supuestos de los modelos trabajados:

```{r}
cumplimientoSupuestos(model5eje1)
```


```{r}
cumplimientoSupuestos(model4eje1)
```
```{r}
cumplimientoSupuestos(model3eje1)
```
```{r}
cumplimientoSupuestos(model2eje1)
```
```{r}
cumplimientoSupuestos(modeleje1)
```
función para encontrar la mejor transformación box y cox

```{r}
mejorBoxYCox<- function(independiente, dependiente,datos){
  box_cox_result <- boxcox(independiente ~ dependiente, lambda = -2:2, data = datos)
  
  # Se encuentra el valor óptimo de lambda que maximiza el logaritmo de verosimilitud
  best_box_cox <- box_cox_result$x[which.max(box_cox_result$y)]

  # Se ajusta un modelo de regresión lineal utilizando la variable dependiente "precio" elevada a    la     potencia óptima de lambda (best_box_cox) como la variable de respuesta y la variable       independiente "tamanio".
  if (best_box_cox==0){
    model <- lm((independiente)^(best_box_cox) ~ dependiente, data = datos)
    
  } else {
    model <- lm(log10(independiente) ~ dependiente, data = datos)
  }
  
  
  
  return(cumplimientoSupuestos(model))
}

mejorBoxYCox(preciocasas$precio,preciocasas$tamanio,preciocasas)

```
## 4. Eliminar la observación 64 y ajustar nuevamente el segundo modelo evaluando su validez.

```{r}
# Eliminar la observación con id igual a 64
preciocasas_sin_obs64 <- subset(preciocasas, caso != 64)
preciocasas_sin_obs64
```

```{r}
modeleje1p4= lm(precio ~ tamanio, data = preciocasas_sin_obs64 )
summary(modeleje1p4)
```
```{r}
cumplimientoSupuestos(modeleje1p4)
```
Se observa que al retirar la observacion 64 el modelo lineal sensillo cumple los supuesto, ademas el r cuadro mejora a un 75.6%.


```{r}
promedioseje1p4 <- colMeans(preciocasas_sin_obs64)
ggplot(preciocasas_sin_obs64, aes(tamanio, precio)) + 
  geom_point() +
  geom_vline(xintercept=promedioseje1p4[7],linetype="dotted") + 
  geom_hline(yintercept=promedioseje1p4[6],linetype="dotted") +
  geom_smooth(method = "lm", se = TRUE, color = "black") +
  theme_minimal()
```


```{r}
ICcompleto<-predict(modeleje1p4, interval="confidence",level=0.95)
IPcompleto<-predict(modeleje1p4,newdata=data.frame(tamanio=preciocasas_sin_obs64$tamanio), interval="prediction",level=0.95)
datos<-data.frame(tamanio=preciocasas_sin_obs64$tamanio,precio=preciocasas_sin_obs64$precio,IPcompleto)             

ggplot(data = datos, mapping = aes(x = tamanio, y = precio)) + 
  geom_point(color = "firebrick", size = 2) + 
  labs(title = "Diagrama de dispersión con bandas de confianza y predicción", x = "tamanio") + 
  geom_line(aes(y=lwr), color="red" , linetype="dashed" ) +
  geom_line(aes(y=upr), color="red" , linetype="dashed" ) +
  geom_smooth(method = "lm", se = TRUE, color = "black") + 
  theme_bw() + theme(plot.title = element_text(hjust = 0.5)) 
```

```{r}
#Grafica del primer modelo con el conjunto de datos total
ICcompleto<-predict(modeleje1, interval="confidence",level=0.95)
IPcompleto<-predict(modeleje1,newdata=data.frame(tamanio=preciocasas$tamanio), interval="prediction",level=0.95)
datos<-data.frame(tamanio=preciocasas$tamanio,precio=preciocasas$precio,IPcompleto)             

ggplot(data = datos, mapping = aes(x = tamanio, y = precio)) + 
  geom_point(color = "firebrick", size = 2) + 
  labs(title = "Diagrama de dispersión con bandas de confianza y predicción", x = "tamanio") + 
  geom_line(aes(y=lwr), color="red" , linetype="dashed" ) +
  geom_line(aes(y=upr), color="red" , linetype="dashed" ) +
  geom_smooth(method = "lm", se = TRUE, color = "black") + 
  theme_bw() + theme(plot.title = element_text(hjust = 0.5))
```

```{r}
#GRafica del mejor modelo con transformacion
ICcompleto<-predict(model5eje1, interval="confidence",level=0.95)
IPcompleto<-predict(model5eje1,newdata=data.frame(tamanio=preciocasas$tamanio), interval="prediction",level=0.95)
datos<-data.frame(tamanio=preciocasas$tamanio,precio=preciocasas$precio,IPcompleto)             

ggplot(data = datos, mapping = aes(x = tamanio, y = precio)) + 
  geom_point(color = "firebrick", size = 2) + 
  labs(title = "Diagrama de dispersión con bandas de confianza y predicción", x = "tamanio") + 
  geom_line(aes(y=lwr), color="red" , linetype="dashed" ) +
  geom_line(aes(y=upr), color="red" , linetype="dashed" ) +
  geom_smooth(method = "lm", se = TRUE, color = "black") + 
  theme_bw() + theme(plot.title = element_text(hjust = 0.5))
```



función grafica con intervalos
```{r}
graficaMLIntervalos <- function(modelolineal,independiente,dependiente,dataset){
  ICcompleto<-predict(modelolineal, interval="confidence",level=0.95)
  IPcompleto<-predict(modelolineal,newdata=data.frame(independiente), interval="prediction",level=0.95)
  datos<-data.frame(independiente,dependiente,IPcompleto)             

 grafica <- ggplot(data = datos, mapping = aes(x = independiente, y = precio)) + 
    geom_point(color = "firebrick", size = 2) + 
    labs(title = "Diagrama de dispersión con bandas de confianza y predicción", x = "tamanio") + 
    geom_line(aes(y=lwr), color="red" , linetype="dashed" ) +
    geom_line(aes(y=upr), color="red" , linetype="dashed" ) +
    geom_smooth(method = "lm", se = TRUE, color = "black") + 
    theme_bw() + theme(plot.title = element_text(hjust = 0.5))
 
 return(grafica)
}

```

```{r}
tamanio=preciocasas_sin_obs64$tamanio
precio=preciocasas_sin_obs64$precio
graficaMLIntervalos(modeleje1p4,tamanio,precio,preciocasas_sin_obs64)
```
```{r}
graficaMLIntervalos(model5eje1,tamanio,precio,preciocasas)
```

## 5. Ajustar un modelo robusto y evaluar el promedio de los errores absolutos cometidos. Comparar con el mejor modelo lineal disponible.

```{r}
library(robustbase)
ajusterobP5 <- lmrob(precio ~ ., data = preciocasas)
summary(ajusterobP5)
```


```{r}
#promedio de los errores absolutos del modelo robusto
# Acceder al resumen del modelo
resumen_modelo <- summary(ajusterobP5)

# Obtener los residuos del modelo
residuos <- resumen_modelo$residuals

# Calcular el promedio de los errores absolutos
promedio_errores_absolutos <- mean(abs(residuos))

promedio_errores_absolutos
```
```{r}
#promedio de los errores absolutos del mejor modelo lineal (model5eje1) #este fue tranformado para el cumplimiento de los supuestos
# Acceder al resumen del modelo
resumen_modelo2 <- summary(model5eje1)

# Obtener los residuos del modelo
residuos2 <- resumen_modelo2$residuals

# Calcular el promedio de los errores absolutos
promedio_errores_absolutos_Mejor_ML <- mean(abs(residuos2))

promedio_errores_absolutos_Mejor_ML
```
Se observa un mayor error promedio de los errores en el modelo robusto que en el lineal.


## 6. Utilizar un método de selección de variables para proponer un modelo multivariado. Analizar el cumplimiento de los supuestos.

```{r}
require(leaps)
mejores_modelos <- regsubsets(precio ~ ., data = preciocasas, nvmax = 5) 
summary(mejores_modelos)
```

```{r}
summary(mejores_modelos)$adjr2
```
```{r}
# se identifica qué modelo tiene el valor máximo de R ajustado 
which.max(summary(mejores_modelos)$adjr2)
```
```{r}
library(ggplot2) 
p <- ggplot(data = data.frame(n_predictores = 1:5, R_ajustado = summary(mejores_modelos)$adjr2), aes(x = n_predictores, y = R_ajustado)) + 
  geom_line() + 
  geom_point() 
# Se identifica en rojo el máximo 
p <- p + geom_point(aes(x=n_predictores[which.max(summary(mejores_modelos)$adjr2)], y=R_ajustado[which.max(summary(mejores_modelos)$adjr2)]), colour = "red", size = 3) 
p <- p + scale_x_continuous(breaks = c(0:5)) + theme_bw() + 
  labs(title = "R2_ajustado vs número de predictores", x = "número predictores") 
p
```
```{r}
coef(object = mejores_modelos, id = 5)
```

```{r}
mejores_modelos_backward <- regsubsets(precio ~ ., data = preciocasas, nvmax = 5, method = "backward") 
# se identifica el valor máximo de R ajustado 
which.max(summary(mejores_modelos_backward)$adjr2)
```
```{r}
coef(object = mejores_modelos_backward, 5)
```
```{r}
mejores_modelos_forward <- regsubsets(precio ~ ., data = preciocasas, nvmax = 5, method = "forward") 
# se identifica el valor máximo de R ajustado 
which.max(summary(mejores_modelos_forward)$adjr2)
```

```{r}
coef(object = mejores_modelos_forward, 5)
```

Todas las combinaciones de modelos
```{r}
library(olsrr)
lm.fit1 <- lm(precio ~ ., data = preciocasas)
k <- ols_step_all_possible(lm.fit1)

# AIC: Akaike Information Criteria 
# SBIC: Sawa's Bayesian Information Criteria 
# SBC: Schwarz Bayesian Criteria 
# MSEP: Estimated error of prediction, assuming multivariate normality 
# FPE: Final Prediction Error 
# HSP: Hocking's Sp 
# APC: Amemiya Prediction Criteria

k # OJO: en RStudio se ven menos columnas en la salida
```
```{r}
plot(k)# el eje horizontal representa la cantidad de variables utilizadas en cada modelo.
```
```{r}
k_best <- ols_step_best_subset(lm.fit1)

# AIC: Akaike Information Criteria 
# SBIC: Sawa's Bayesian Information Criteria 
# SBC: Schwarz Bayesian Criteria 
# MSEP: Estimated error of prediction, assuming multivariate normality 
# FPE: Final Prediction Error 
# HSP: Hocking's Sp 
# APC: Amemiya Prediction Criteria

k_best
```
```{r}
plot(k_best)# el eje horizontal representa la cantidad de variables utilizadas en cada modelo.
```

```{r}
modeleje1P6= lm(precio ~ tamanio+caso+impuestos+estrena, data = preciocasas )
summary(modeleje1P6)
```
```{r}
#modelo lineal simple con la seleccion de las mejores variables
cumplimientoSupuestos(modeleje1P6)
```
```{r}
#modelo lineal simple transformado con la seleccion de las mejores variables
model2eje1P6= lm(log10(precio) ~ log10(tamanio+caso+impuestos+estrena), data = preciocasas )
summary(model2eje1P6)
```
```{r}
cumplimientoSupuestos(model2eje1P6)
```
```{r}
#modelo lineal robusto con la seleccion de las mejores variables
ajusterobP6 <- lmrob(precio ~ tamanio+caso+impuestos+estrena, data = preciocasas)
summary(ajusterobP6)
```

```{r}
cumplimientoSupuestos(ajusterobP6)
```
Se observa el cumplimiento de los supuestos sobre el modelo con transformación, en tal sentido, el mejor modelo que explica la variabilidad del precio en función del tamaño es model2eje1P6, un modelo lineal simple con transformación, con un R cuadrado de 75.29%.


## 7. Le parece adecuado un modelo GAMLSS en este caso? Justifique.

```{r}
mod_OLS <- gamlss( formula = precio ~ pb(tamanio)+caso+impuestos+estrena, family = NO, data = preciocasas, trace = FALSE)
summary(mod_OLS)
```


```{r}
plot(mod_OLS)
```
```{r}
cumplimientoSupuestos(mod_OLS)
```
```{r}
wp(mod_OLS)
```


```{r}

mod_GAMLSS <- gamlss(formula = precio ~ pb(tamanio)+caso+impuestos+estrena, sigma.formula = ~ pb(tamanio)+caso+impuestos+estrena, family = GA, data = preciocasas, trace = FALSE )
summary(mod_GAMLSS)
```

```{r}
plot(mod_GAMLSS)
```


```{r}
cumplimientoSupuestos(mod_GAMLSS)
```


```{r}
# Efecto individuales de los Predictores (GAMLSS)
term.plot(mod_GAMLSS, parameter = 'sigma',ask = FALSE, rug = TRUE)
```

```{r}
# Contribución de cada uno de los predictores (GAMLSS)
drop1(mod_GAMLSS, parameter = 'sigma', parallel = 'multicore', ncpus = 4)
```
```{r}
drop1(mod_GAMLSS, parameter = 'mu', parallel = 'multicore', ncpus = 4)
```

```{r}
mod_GAMLSS2 <- gamlss(formula = precio ~ pb(tamanio)+caso+impuestos+estrena, sigma.formula = ~ pb(tamanio), family = GA, data = preciocasas, trace = FALSE )
summary(mod_GAMLSS2)
```

```{r}
plot(mod_GAMLSS2)
```

```{r}
cumplimientoSupuestos(mod_GAMLSS2) #creo que esta funcion solo serviria para modelos lineales simple, pendiente de validar
```


```{r}
# Contribución de cada uno de los predictores (GAMLSS)
drop1(mod_GAMLSS2, parameter = 'sigma', parallel = 'multicore', ncpus = 4)
drop1(mod_GAMLSS2, parameter = 'mu', parallel = 'multicore', ncpus = 4)
```
```{r}
# Worm plot de los residuos modelo 1
wp(mod_GAMLSS, ylim.all = 0.5)
```
```{r}
# Worm plot de los residuos modelo 2
wp(mod_GAMLSS2, ylim.all = 0.5)
```
La inspección visual del wormplot de los dos modelos GAMLSS indica que estos modelos tienen los
residuos dentro del rango de variación aceptable.

```{r}
#Comparamos los modelos ajustados:
GAIC(mod_OLS,mod_GAMLSS, mod_GAMLSS2)
```

De acuerdo con el criterio GAIC, el modelo GAMLSS2 es el que mejor explica la relación con el precio utilizando los mismos predictores.

En tal sentido, si sería adecuado utilizar modelos GAMLSS debido a que con estos se puede analizar conjuntos de datos que tengan comportamientos no lineales y exista presencia de heterocedasticidad.

## 8. Resuma sus conclusiones.

En general se puede concluir que del conjunto de datos preciocasas, la variable precio se puede predecir en función de la variable tamanio, esta variable tiene un comportamiento no lineal y la implementación de modelos GAMLSS permite una mejor interpretación del modelo.  


# <span style="color:darkred">Ejercicio 2 </span>

Se desea saber si la dosis de ácido ascórbico y el tipo de bebida en la cual se lo administró a ciertos animales de
laboratorio logró mayor desarrollo de los dientes en los mismo. Se utilizaron 60 replicaciones del experimento y se tienen grupos balanceados. La variable respuesta de interés es la longitud de los dientes frontales(len). Los resultados están en el archivo odonto.csv Se pide analizar, analítica y gráficamente, si:

```{r}
odonto<-read.csv("C:/Users/Josvaldes/Documents/Maestria/Austral/1ano/regresionAvanzada/TPRegresion/TPRegresion/examen/prueba/odonto.csv")
odonto
```


## 1. Existen diferencias estadísticamente significativas respecto de las dosis administradas?

Se Compara los resultados según los niveles de ambas categorías.

```{r}
library(ggplot2) 
library(gridExtra)

# Se convierte la variables dose en factor
odonto$dose<-factor(odonto$dose)
odonto$supp<-factor(odonto$supp)

p1 <- ggplot(data = odonto, mapping = aes(x = dose, y = len)) + geom_boxplot() + 
  theme_bw() 
p2 <- ggplot(data = odonto, mapping = aes(x = supp, y = len)) + geom_boxplot() + 
  theme_bw() 
p3 <- ggplot(data = odonto, mapping = aes(x = dose, y = len, colour = supp)) + 
  geom_boxplot() + theme_bw() 
grid.arrange(p1, p2,p3, ncol = 2)

```
Parece existir interacción de las variables y diferencia de medias entre las categorías de la variable dose.

Análisis de interacciones

```{r}
interaction.plot(trace.factor = odonto$supp, x.factor = odonto$dose, response = odonto$len, fun = "mean", legend = TRUE, col = 2:3, type = "b")
```
Se observa que parece que existe interacción entre las variables dose y supp.

```{r}
interaction.plot(trace.factor = odonto$dose, x.factor = odonto$supp, response = odonto$len, fun = "mean", legend = TRUE, col = 2:3, type = "b")
```
Para el caso de validar la interacción entre las variables trazando desde la variable dose no se logra ver interacción.

```{r}
ggplot(data = odonto, aes(x = dose, y = len, colour = supp, group = supp)) + 
  stat_summary(fun = mean, geom = "point") + stat_summary(fun.y = mean, geom = "line") + 
  labs(y = "mean (resultado)") + theme_bw()
```
Se repite la primera grafica de interacción con otro comando y se obtiene una gráfica parecida, se concluye que existe una interacción entre las variables categóricas dose y supp.

```{r}
anova_2vias <- aov(formula = len ~ dose*supp, data = odonto) 
summary(anova_2vias)
```
En base a los resultados:

El factor dose muestra un efecto significativo en la variable respuesta (len) debido a que el valor de p es extremadamente pequeño (< 2e-16). Esto indica que la dosis tiene un impacto estadísticamente significativo en len.

El factor supp también tiene un efecto significativo en len con un valor de p de 0.000231. Esto sugiere que el tipo de suplemento tiene un impacto significativo en la variable respuesta.

Además, la interacción entre dose y supp también es significativa con un valor de p de 0.021860. Esto indica que el efecto de la dosis sobre la variable respuesta depende del tipo de suplemento utilizado.

En general, estos resultados sugieren que tanto la dosis como el tipo de suplemento tienen un impacto significativo en la variable respuesta len, y que la interacción entre ambos factores también es relevante.

```{r}
library(lsr)
etaSquared(anova_2vias)
```
Para el factor dose, el coeficiente eta cuadrado (eta.sq) es 0.70286419, lo que indica que el 70.29% de la variabilidad total de la variable respuesta (len) se puede explicar por la variabilidad en el factor dose. Esto sugiere que dose tiene un efecto muy grande y explica una cantidad significativa de la variabilidad observada en la variable respuesta.

El coeficiente eta cuadrado parcial (eta.sq.part) para el factor dose es 0.7731092. Este valor indica la proporción de la variabilidad única explicada por dose, es decir, el efecto exclusivo de dose en la variable respuesta después de considerar otros factores en el modelo. En este caso, el 77.31% de la variabilidad única en len se puede atribuir al factor dose.

Para el factor supp, el coeficiente eta cuadrado (eta.sq) es 0.05948365, lo que indica que el 5.95% de la variabilidad total en len se puede explicar por la variabilidad en el factor supp. Esto sugiere que supp tiene un efecto más pequeño en comparación con dose en la explicación de la variabilidad en la variable respuesta.

El coeficiente eta cuadrado parcial (eta.sq.part) para el factor supp es 0.2238254. Esto indica que el 22.38% de la variabilidad única en len se puede atribuir al factor supp después de tener en cuenta otros factores en el modelo.

Para la interacción entre dose y supp (dose:supp), el coeficiente eta cuadrado (eta.sq) es 0.03137672, lo que indica que el 3.14% de la variabilidad total en len se puede explicar por la variabilidad en la interacción. Este valor sugiere que la interacción entre dose y supp también contribuye de manera significativa a la variabilidad en la variable respuesta.

Finalmente el coeficiente eta cuadrado parcial (eta.sq.part) de la interacción entre dose y supp es 0.1320279. Esto indica que el 13.20% de la variabilidad única en len se puede atribuir a la interacción entre dose y supp después de considerar otros factores en el modelo.

En resumen, los coeficientes eta cuadrado indican la proporción de variabilidad explicada por cada factor y su interacción en la variable respuesta, mientras que los coeficientes eta cuadrado parcial reflejan la proporción de variabilidad única explicada por cada factor después de considerar otros factores en el modelo. En este caso, dose tiene el mayor efecto en len, seguido por supp y la interacción entre ambos factores.

```{r}
par(mfrow = c(2,2)) 
plot(anova_2vias)
```
El resumen de los gráficos del modelo muestra al parecer el cumplimiento de los supuestos. Estos son analizados en el sub numeral 4.

Con relación a la pregunta incial, sí existen diferencias estadísticamente significativas respecto de las dosis administradas. Esto se puede deducir de la salida del análisis de varianza de dos vías (ANOVA de dos vías):

El factor dose muestra un efecto significativo en la variable respuesta (len) debido a que el valor de p es extremadamente pequeño (< 2e-16). Esto indica que la dosis tiene un impacto estadísticamente significativo en len.
El valor de p extremadamente pequeño (< 2e-16) indica que la probabilidad de obtener una diferencia tan grande o mayor entre las medias de las dosis por pura casualidad es extremadamente baja. Por lo tanto, podemos concluir que hay diferencias estadísticamente significativas en la variable respuesta (len) entre las diferentes dosis administradas.

En resumen, el análisis de varianza indica que existe una diferencia estadísticamente significativa en la variable respuesta (len) en función de las dosis administradas.

## 2. Existen diferencias estadísticamente singificativas respecto del tipo de vehículo de administración?

Sí, existen diferencias estadísticamente significativas respecto del tipo de vehículo de administración. Esto se puede deducir de la salida del análisis de varianza de dos vías (ANOVA de dos vías):

El factor supp también tiene un efecto significativo en len con un valor de p de 0.000231. Esto sugiere que el tipo de vehículo de administración tiene un impacto significativo en la variable respuesta.
El valor de p extremadamente pequeño (0.000231) indica que la probabilidad de obtener una diferencia tan grande o mayor entre las medias de los diferentes tipos de vehículo de administración por pura casualidad es extremadamente baja. Por lo tanto, podemos concluir que hay diferencias estadísticamente significativas en la variable respuesta (len) entre los diferentes tipos de vehículo de administración.

En resumen, el análisis de varianza indica que existe una diferencia estadísticamente significativa en la variable respuesta (len) en función del tipo de vehículo de administración.

## 3. La interacción entre estas variables es significativa?

Sí, la interacción entre las variables dose (dosis administrada) y supp (tipo de vehículo de administración) es significativa. Esto se puede deducir de la salida del análisis de varianza de dos vías (ANOVA de dos vías):

La interacción dose:supp también es significativa con un valor de p de 0.021860. Esto indica que el efecto de la dosis sobre la variable respuesta depende del tipo de vehículo de administración utilizado.

El valor de p (0.021860) por debajo de un umbral de significancia (como 0.05) indica que la probabilidad de obtener una interacción tan grande o mayor entre las dos variables por pura casualidad es baja. Por lo tanto, podemos concluir que hay una interacción estadísticamente significativa entre las variables dose y supp en relación con la variable respuesta (len).

En resumen, el análisis de varianza indica que la interacción entre las variables dose y supp es estadísticamente significativa. Esto implica que el efecto de la dosis sobre la variable respuesta (len) difiere según el tipo de vehículo de administración utilizado.

## 4. Se satisfacen los supuestos del modelo?

Se implementa la función de cumplimiento de modelos definida con anterioridad
```{r}
cumplimientoSupuestos(anova_2vias)
```
Se observa que, si se satisfacen los supuestos del modelo, siendo los residuos normales, homocedasticos e independientes.


## 5. Puede realizar una recomendación?

Basado en los resultados del análisis de varianza de dos vías, donde se encontraron diferencias estadísticamente significativas tanto para la dosis administrada como para el tipo de vehículo de administración, así como una interacción significativa entre ambas variables, se podria recomendar lo siguiente:

Dado que tanto la dosis administrada como el tipo de vehículo de administración tienen un impacto significativo en la variable respuesta (len), es importante considerar estas variables al tomar decisiones relacionadas con el tratamiento o intervención en el contexto del estudio.

Recomendaría analizar más a fondo las relaciones entre la dosis administrada y el tipo de vehículo de administración en relación con los efectos observados en len. Esto podría implicar realizar análisis adicionales o realizar comparaciones más detalladas entre los diferentes niveles de dosis y los diferentes tipos de vehículo de administración.

Además, dado que se encontró una interacción significativa entre la dosis y el tipo de vehículo de administración, se sugiere investigar la naturaleza de esta interacción y cómo afecta la variable respuesta. Puede ser útil realizar análisis de subgrupos o realizar comparaciones específicas entre los diferentes niveles de dosis dentro de cada tipo de vehículo de administración.

En general, al considerar las diferencias significativas encontradas en el estudio, es importante tener en cuenta tanto la dosis administrada como el tipo de vehículo de administración al diseñar estrategias de tratamiento o intervención y al interpretar los resultados obtenidos.

# <span style="color:darkred">Ejercicio 3 </span>

En el archivo morosos.xlsx se encuentran los registros de 10 mil clientes de un banco para los cuales se relevaron
las siguientes variables:
• mora: si está en mora con el saldo de su tarjeta de crédito.
• estudiantes: si es estudiante o no.
• balance: el saldo al 31/12 próximo pasado.
• ingreso: ingreso mensual medio del cliente.

```{r}
morosos<-read_excel("C:/Users/Josvaldes/Documents/Maestria/Austral/1ano/regresionAvanzada/TPRegresion/TPRegresion/examen/prueba/morosos.xlsx")
morosos
```


Se desea modelar la probabilidad de mora de un cliente en función de las variables disponibles en la base.
Se pide:


# 1. Ajustar un modelo logístico para predecir la probabilidad de incurrir en mora.

```{r}

# Crear una nueva variable binaria para representar 'mora'
morosos$bin_mora <- ifelse(morosos$mora == "Yes", 1, 0)

# Ajustar el modelo logístico con la nueva variable binaria
modelo_logistico <- glm(bin_mora ~ ingreso, data = morosos, family = "binomial")

# Realizar el análisis del modelo
summary(modelo_logistico)

```
Intercepto: El valor estimado del intercepto es de -3.094, lo cual indica el logaritmo de la razón de probabilidad de que la variable respuesta sea igual a 1 cuando la variable ingreso es igual a 0. Un valor negativo indica que la probabilidad de que ocurra el evento es menor.

Coeficiente de ingreso: El valor estimado del coeficiente de ingreso es de -8.353e-06. Este coeficiente representa el cambio en el logaritmo de la razón de probabilidad de la variable respuesta por cada unidad de cambio en la variable ingreso. En este caso, un incremento en ingreso se asocia con una disminución en la probabilidad de que ocurra el evento.

Significancia estadística: El coeficiente de ingreso es significativamente diferente de cero con un valor p de 0.0471. Esto indica que existe evidencia estadística para sugerir que la variable ingreso tiene un efecto significativo en la variable respuesta bin_mora.

Deviance residuals: Los residuos de deviance son medidas de ajuste del modelo y cuantifican la discrepancia entre las respuestas observadas y las predichas por el modelo. Los valores oscilan entre -0.2968 y 2.7111, y se espera que estén cerca de cero.

AIC: El valor de AIC (Akaike Information Criterion) del modelo es de 2920.7. El AIC es una medida de la calidad del ajuste del modelo, y un valor más bajo indica un mejor ajuste.

En resumen, el modelo logístico muestra que la variable ingreso tiene un efecto estadísticamente significativo en la probabilidad de que ocurra el evento representado por la variable bin_mora. Sin embargo, se observa que el coeficiente estimado para ingreso es muy pequeño, lo que indica una asociación débil entre la variable predictora y la variable respuesta.

```{r}
#validación de las demas variables
# Ajustar el modelo logístico con la nueva variable binaria
modelo_logistico2 <- glm(bin_mora ~ estudiante, data = morosos, family = "binomial")

# Realizar el análisis del modelo
summary(modelo_logistico2)
```
Se observa que la variable estudiante es significativa.

```{r}
#validación de las demas variables
# Ajustar el modelo logístico con la nueva variable binaria
modelo_logistico3 <- glm(bin_mora ~ balance, data = morosos, family = "binomial")

# Realizar el análisis del modelo
summary(modelo_logistico3)
```
La variable balance tambien es significativa.

```{r}
#validación dcon todas variables
# Ajustar el modelo logístico con la nueva variable binaria
modelo_logistico4 <- glm(bin_mora ~ ingreso+estudiante+balance, data = morosos, family = "binomial")

# Realizar el análisis del modelo
summary(modelo_logistico4)
```
Con todas la variables se observa que se reduce el AIC y la variable ingreso deja de ser signiticativa.

```{r}
library(lmtest)
#Prueba de verosimilitud
lrtest<-lrtest(modelo_logistico, modelo_logistico4)
lrtest
```
El test de razón de verosimilitud sugiere que el modelo 2 (bin_mora ~ ingreso + estudiante + balance) proporciona un ajuste significativamente mejor que el modelo 1 (bin_mora ~ ingreso), lo que implica que la inclusión de las variables estudiante y balance mejora la capacidad de predicción de la variable respuesta bin_mora.

```{r}
#Validación del AIC
modelo_logistico$aic
modelo_logistico2$aic
modelo_logistico3$aic
modelo_logistico4$aic
```
Por el critero de AIC se observa que el modelo 4 es el que mejor ajusta.

```{r}
# Validación de un quinto modelo sin la variable ingreso
# Ajustar el modelo logístico con la nueva variable binaria
modelo_logistico5 <- glm(bin_mora ~ estudiante+balance, data = morosos, family = "binomial")

# Realizar el análisis del modelo
summary(modelo_logistico5)
```
```{r}
lrtest(modelo_logistico4, modelo_logistico5)
```
El test de razón de verosimilitud sugiere que no hay evidencia suficiente para concluir que el modelo 2 (bin_mora ~ estudiante + balance) proporciona un ajuste significativamente mejor que el modelo 1 (bin_mora ~ ingreso + estudiante + balance). Por lo tanto, no se justifica eliminar la variable ingreso del modelo.

# 2. Evaluar la calidad de ajuste del modelo con al menos dos criterios distintos.

Para evaluar la calidad de ajuste del modelo logístico, se pueden utilizar varios criterios. A continuación, se presentan dos criterios comunmente utilizados:

Deviance: La deviance es una medida de la discrepancia entre el modelo ajustado y los datos observados. Un valor de deviance más bajo indica un mejor ajuste del modelo. Se puede comparar la deviance del modelo ajustado con la deviance del modelo nulo (modelo sin covariables) para evaluar la mejora en el ajuste. Si la deviance del modelo ajustado es significativamente más baja que la del modelo nulo, indica que el modelo tiene un buen ajuste.

AIC (Akaike Information Criterion): El criterio de información de Akaike es una medida de la calidad del ajuste del modelo que tiene en cuenta la complejidad del modelo. Se calcula utilizando la deviance del modelo y el número de parámetros del modelo. Un valor de AIC más bajo indica un mejor ajuste del modelo. Al comparar diferentes modelos, el modelo con un AIC más bajo se considera preferido.
# 3. Interpretar los coeficientes del modelo elegido.
# 4. Evaluar la calidad de clasificación y compararlo con otro método de clasificación.

